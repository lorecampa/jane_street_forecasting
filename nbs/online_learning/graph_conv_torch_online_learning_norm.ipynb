{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:18.101283Z",
     "iopub.status.busy": "2025-01-07T16:43:18.100944Z",
     "iopub.status.idle": "2025-01-07T16:43:25.885197Z",
     "shell.execute_reply": "2025-01-07T16:43:25.884420Z",
     "shell.execute_reply.started": "2025-01-07T16:43:18.101254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import kaggle_evaluation.jane_street_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/random.py:46\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/cuda/random.py:129\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    126\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    127\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 129\u001b[0m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:249\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 249\u001b[0m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/cuda/random.py:127\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    126\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 127\u001b[0m     \u001b[43mdefault_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:25.886712Z",
     "iopub.status.busy": "2025-01-07T16:43:25.886330Z",
     "iopub.status.idle": "2025-01-07T16:43:25.894995Z",
     "shell.execute_reply": "2025-01-07T16:43:25.893995Z",
     "shell.execute_reply.started": "2025-01-07T16:43:25.886686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MultiStockGraphDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset: pl.LazyFrame, adjacency_matrices: np.ndarray, stock_ids: list):\n",
    "        self.dataset = dataset\n",
    "        self.adjacency_matrices = adjacency_matrices\n",
    "        self.stock_ids = stock_ids\n",
    "        self.num_stocks = len(self.stock_ids)\n",
    "        self.dataset_len = self.dataset.select(['date_id', 'time_id']).unique().shape[0]\n",
    "        self._load()\n",
    "    \n",
    "    def _load(self):\n",
    "        all_combinations = (\n",
    "            self.dataset.select(['date_id', 'time_id'])\n",
    "            .unique()\n",
    "            .join(pl.DataFrame({'symbol_id': self.stock_ids}, \n",
    "                               schema={'symbol_id': pl.Int8}), how=\"cross\")\n",
    "        )\n",
    "        feature_cols = [f'feature_{i:02d}' for i in range(79)]\n",
    "        self.batch = (\n",
    "            all_combinations\n",
    "            .join(self.dataset.with_columns(pl.lit(1).alias('mask')), \n",
    "                  on=['date_id', 'time_id', 'symbol_id'], how=\"left\")\n",
    "            .fill_null(0)  # fill all columns with 0 for missing stocks (including the mask)\n",
    "            .sort(['date_id', 'time_id', 'symbol_id'])\n",
    "        )\n",
    "        # num_stocks rows for each date and time\n",
    "        self.X = self.batch.select(feature_cols).to_numpy().astype(np.float32)\n",
    "        self.y = self.batch.select(['responder_6']).to_numpy().flatten().astype(np.float32)\n",
    "        self.s = self.batch.select(['symbol_id']).to_numpy().flatten().astype(np.int32)\n",
    "        self.date_ids = self.batch.select(['date_id']).to_numpy().flatten()\n",
    "        self.masks = self.batch.select(['mask']).to_numpy().flatten() == 0\n",
    "        self.weights = self.batch.select(['weight']).to_numpy().flatten().astype(np.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_row = idx * self.num_stocks\n",
    "        features = self.X[start_row:start_row+self.num_stocks, :]\n",
    "        targets = self.y[start_row:start_row+self.num_stocks]\n",
    "        masks = self.masks[start_row:start_row+self.num_stocks]\n",
    "        weights = self.weights[start_row:start_row+self.num_stocks]\n",
    "        symbols = self.s[start_row:start_row+self.num_stocks]\n",
    "\n",
    "        date_id = self.date_ids[start_row]\n",
    "        adj_matrix = self.adjacency_matrices[date_id]\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(features), \n",
    "            torch.tensor(targets), \n",
    "            torch.tensor(masks), \n",
    "            torch.tensor(weights), \n",
    "            torch.tensor(symbols),\n",
    "            torch.tensor(adj_matrix, dtype=torch.int)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:25.896262Z",
     "iopub.status.busy": "2025-01-07T16:43:25.896030Z",
     "iopub.status.idle": "2025-01-07T16:43:25.925219Z",
     "shell.execute_reply": "2025-01-07T16:43:25.923954Z",
     "shell.execute_reply.started": "2025-01-07T16:43:25.896215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransposeLayer(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return input.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:25.926500Z",
     "iopub.status.busy": "2025-01-07T16:43:25.926182Z",
     "iopub.status.idle": "2025-01-07T16:43:25.944211Z",
     "shell.execute_reply": "2025-01-07T16:43:25.943298Z",
     "shell.execute_reply.started": "2025-01-07T16:43:25.926472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "    \n",
    "    def forward(self, predictions: Tensor, targets: Tensor, weights: Tensor) -> Tensor:\n",
    "        squared_diff = (predictions - targets) ** 2\n",
    "        weighted_squared_diff = weights * squared_diff\n",
    "        return weighted_squared_diff.sum() / weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:25.945265Z",
     "iopub.status.busy": "2025-01-07T16:43:25.945032Z",
     "iopub.status.idle": "2025-01-07T16:43:25.956540Z",
     "shell.execute_reply": "2025-01-07T16:43:25.955322Z",
     "shell.execute_reply.started": "2025-01-07T16:43:25.945221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GraphConvEncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, dim_feedforward_mult=4, dropout_rate=0.1):\n",
    "        super(GraphConvEncoderLayer, self).__init__()\n",
    "        \n",
    "        self.graph_conv = GCNConv(\n",
    "            in_channels=hidden_dim, \n",
    "            out_channels=hidden_dim\n",
    "        )\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * dim_feedforward_mult),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim * dim_feedforward_mult, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        batch_size, num_nodes, num_features = x.size()\n",
    "\n",
    "        residual = x\n",
    "        x = x.reshape(batch_size * num_nodes, num_features)\n",
    "        x = self.graph_conv(x, edge_index)\n",
    "        x = x.reshape(batch_size, num_nodes, num_features)        \n",
    "        x = self.dropout1(x) + residual\n",
    "        # x = self.norm1(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.feedforward(x)\n",
    "        x = self.dropout2(x) + residual\n",
    "        # x = self.norm2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:25.957527Z",
     "iopub.status.busy": "2025-01-07T16:43:25.957307Z",
     "iopub.status.idle": "2025-01-07T16:43:25.980770Z",
     "shell.execute_reply": "2025-01-07T16:43:25.979637Z",
     "shell.execute_reply.started": "2025-01-07T16:43:25.957506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GraphConvEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, dim_feedforward_mult=4, dropout_rate=0.1):\n",
    "        super(GraphConvEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            GraphConvEncoderLayer(\n",
    "                hidden_dim=hidden_dim,\n",
    "                dim_feedforward_mult=dim_feedforward_mult,\n",
    "                dropout_rate=dropout_rate\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        batch_size, num_nodes, _ = x.size()\n",
    "\n",
    "        edge_indices = []\n",
    "        for batch_idx in range(batch_size):\n",
    "            adj_matrix = adj[batch_idx]\n",
    "            src, tgt = torch.nonzero(adj_matrix, as_tuple=True)\n",
    "            src = src + batch_idx * num_nodes\n",
    "            tgt = tgt + batch_idx * num_nodes\n",
    "            edge_indices.append(torch.stack([src, tgt], dim=0))\n",
    "\n",
    "        edge_index = torch.cat(edge_indices, dim=1).to(x.device)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:25.983573Z",
     "iopub.status.busy": "2025-01-07T16:43:25.983295Z",
     "iopub.status.idle": "2025-01-07T16:43:26.007782Z",
     "shell.execute_reply": "2025-01-07T16:43:26.006646Z",
     "shell.execute_reply.started": "2025-01-07T16:43:25.983549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class StockGCNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_features,\n",
    "        hidden_dim=64,\n",
    "        output_dim=1,\n",
    "        num_layers=2,\n",
    "        num_stocks=39,\n",
    "        embedding_dim=16,\n",
    "        use_embeddings=False,\n",
    "        dropout_rate=0.2,\n",
    "        dim_feedforward_mult=4,\n",
    "    ):\n",
    "        super(StockGCNModel, self).__init__()\n",
    "\n",
    "        self.use_embeddings = use_embeddings\n",
    "\n",
    "        self.init_layers = nn.Sequential(\n",
    "            # TransposeLayer(),\n",
    "            # nn.BatchNorm1d(input_features),\n",
    "            # TransposeLayer(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.feature_projector = []\n",
    "        if use_embeddings:\n",
    "            self.feature_projector.append(nn.Linear(input_features + embedding_dim, hidden_dim))\n",
    "            self.embedding_layer = nn.Embedding(num_stocks, embedding_dim)\n",
    "        else:\n",
    "            self.feature_projector.append(nn.Linear(input_features, hidden_dim))\n",
    "        self.feature_projector += [\n",
    "            # TransposeLayer(),\n",
    "            # nn.BatchNorm1d(hidden_dim),\n",
    "            # TransposeLayer(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        ]\n",
    "        self.feature_projector = nn.Sequential(*self.feature_projector)\n",
    "\n",
    "        self.encoder = GraphConvEncoder(\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dim_feedforward_mult=dim_feedforward_mult,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            # TransposeLayer(),\n",
    "            # nn.BatchNorm1d(hidden_dim),\n",
    "            # TransposeLayer(),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, symbols, adj):\n",
    "        batch_size, num_stocks, num_features = x.size()\n",
    "\n",
    "        x = self.init_layers(x)\n",
    "        if self.use_embeddings:\n",
    "            stock_embeddings = self.embedding_layer(symbols)\n",
    "            x = torch.cat([x, stock_embeddings], dim=-1)\n",
    "        x = self.feature_projector(x)\n",
    "        x = self.encoder(x, adj)\n",
    "\n",
    "        output = self.predictor(x)\n",
    "        return 5 * torch.tanh(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:26.009269Z",
     "iopub.status.busy": "2025-01-07T16:43:26.009025Z",
     "iopub.status.idle": "2025-01-07T16:43:26.034264Z",
     "shell.execute_reply": "2025-01-07T16:43:26.033334Z",
     "shell.execute_reply.started": "2025-01-07T16:43:26.009251Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_correlation_from_pivot(pivot_df):\n",
    "    correlations = (\n",
    "        pivot_df\n",
    "        .drop(['date_id', 'time_id'])\n",
    "        .corr()\n",
    "        .fill_nan(0).fill_null(0)\n",
    "    )\n",
    "    order = [int(i) for i in correlations.columns]\n",
    "    new_order = np.argsort(order).tolist()\n",
    "    columns_order = [str(i) for i in np.array(order)[new_order].tolist()]\n",
    "    correlations = correlations[columns_order]\n",
    "    correlations = correlations[new_order, :]\n",
    "    return np.abs(correlations.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:26.035219Z",
     "iopub.status.busy": "2025-01-07T16:43:26.035023Z",
     "iopub.status.idle": "2025-01-07T16:43:26.056182Z",
     "shell.execute_reply": "2025-01-07T16:43:26.055317Z",
     "shell.execute_reply.started": "2025-01-07T16:43:26.035201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:26.057258Z",
     "iopub.status.busy": "2025-01-07T16:43:26.057061Z",
     "iopub.status.idle": "2025-01-07T16:43:26.209251Z",
     "shell.execute_reply": "2025-01-07T16:43:26.208319Z",
     "shell.execute_reply.started": "2025-01-07T16:43:26.057241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockGCNModel(\n",
       "  (init_layers): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (feature_projector): Sequential(\n",
       "    (0): Linear(in_features=79, out_features=64, bias=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (encoder): GraphConvEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): GraphConvEncoderLayer(\n",
       "        (graph_conv): GCNConv(64, 64)\n",
       "        (feedforward): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictor): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = '/home/lorecampa/projects/jane_street_forecasting/dataset/models/graph_conv/model_4_7_norm_nolayer.pth'\n",
    "model = StockGCNModel(\n",
    "    input_features=79,\n",
    "    output_dim=1,\n",
    "    num_layers=1,\n",
    "    dropout_rate=0.2,\n",
    "    dim_feedforward_mult=4,\n",
    "    hidden_dim=64)\n",
    "model.load_state_dict(torch.load(save_path, weights_only=True, map_location=torch.device(device)))\n",
    "model = model.to(device)\n",
    "inference_model = StockGCNModel(\n",
    "    input_features=79,\n",
    "    output_dim=1,\n",
    "    num_layers=1,\n",
    "    dropout_rate=0.2,\n",
    "    dim_feedforward_mult=4,\n",
    "    hidden_dim=64)\n",
    "inference_model.load_state_dict(torch.load(save_path, weights_only=True, map_location=torch.device(device)))\n",
    "inference_model = inference_model.to(device)\n",
    "\n",
    "loss_fn = WeightedMSELoss()\n",
    "inference_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:26.210523Z",
     "iopub.status.busy": "2025-01-07T16:43:26.210184Z",
     "iopub.status.idle": "2025-01-07T16:43:26.216476Z",
     "shell.execute_reply": "2025-01-07T16:43:26.215616Z",
     "shell.execute_reply.started": "2025-01-07T16:43:26.210500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from prj.config import DATA_DIR\n",
    "\n",
    "FINE_TUNING = True\n",
    "N_EPOCHS_PER_TRAIN_MAX = 10\n",
    "BATCH_SIZE = 2048\n",
    "OLD_DATA_FRACTION = 0.1\n",
    "FEATURE_COLS = [f'feature_{i:02d}' for i in range(79)]\n",
    "GRADIENT_CLIPPING = 10\n",
    "EARLY_STOPPING_DAYS = 7\n",
    "ES_PATIENCE = 7\n",
    "TRAIN_EVERY = 23\n",
    "date_idx = -1\n",
    "epoch = None\n",
    "best_epoch = None\n",
    "best_score = None\n",
    "train_dataloader, val_dataloader, train_iterator, val_iterator = None, None, None, None\n",
    "save_path = './best_model.pth'\n",
    "acc_metrics = dict(ss_res=0.0, ss_tot=0.0)\n",
    "start_train = False\n",
    "is_training_loop = False\n",
    "\n",
    "gradient_clipping_decay = 0.5\n",
    "gradient_clipping = GRADIENT_CLIPPING * gradient_clipping_decay\n",
    "lr_decay = 0.7\n",
    "lr = 1e-5\n",
    "optimizer = None\n",
    "\n",
    "TIME_LIMIT = 30\n",
    "MAX_FINE_TUNING_TIME_LIMIT = time.time() + 60 * 60 * 8 # after 8 hours, stop all the online learning\n",
    "\n",
    "FEATURES = [f'feature_{i:02d}' for i in range(79)]\n",
    "COLUMNS = FEATURES + ['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']\n",
    "BASE_PATH = DATA_DIR / 'train.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 16:59:49.450472: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-12 16:59:49.450507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-12 16:59:49.451849: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-12 16:59:49.458772: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-12 16:59:50.245987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([33, 36,  4, 13, 30], dtype=int8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prj.data.data_loader import DataLoader as PrjDataLoader\n",
    "from prj.data.data_loader import DataConfig as PrjDataConfig\n",
    "\n",
    "config = PrjDataConfig(**{})\n",
    "loader = PrjDataLoader(data_dir=DATA_DIR, config=config)\n",
    "start, end = 1360, 1529\n",
    "start, end = 1360, 1370\n",
    "\n",
    "# start, end = 1190, 1200\n",
    "test_ds = loader.load(start-1, end).collect()\n",
    "\n",
    "to_remove_symbols = np.random.choice(test_ds['symbol_id'].unique().to_numpy(), size=5, replace=False)\n",
    "test_ds = test_ds.filter(~pl.col('symbol_id').is_in(to_remove_symbols))\n",
    "\n",
    "\n",
    "y_test = test_ds.filter(pl.col('date_id').ge(start))['responder_6'].to_numpy().flatten()\n",
    "w_test = test_ds.filter(pl.col('date_id').ge(start))['weight'].to_numpy().flatten()\n",
    "\n",
    "to_remove_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (391_072, 93)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>&hellip;</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th><th>partition_id</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i64</td></tr></thead><tbody><tr><td>1359</td><td>0</td><td>0</td><td>2.136611</td><td>2.422234</td><td>-0.516497</td><td>2.192171</td><td>2.539526</td><td>2.473287</td><td>-0.481699</td><td>0.879098</td><td>0.548299</td><td>-0.212614</td><td>0.134146</td><td>0.583333</td><td>0.141002</td><td>-1.081436</td><td>2.52483</td><td>-0.062748</td><td>0.0</td><td>-0.373516</td><td>0.0</td><td>-1.620773</td><td>-1.231624</td><td>0.725762</td><td>-0.432059</td><td>0.711123</td><td>0.526897</td><td>-0.203114</td><td>-0.199322</td><td>1.256969</td><td>0.943244</td><td>0.296373</td><td>0.293305</td><td>-0.150386</td><td>-0.865181</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>-0.533592</td><td>0.0</td><td>-1.739991</td><td>2.93767</td><td>0.0</td><td>1.811655</td><td>1.190002</td><td>3.851669</td><td>0.088155</td><td>0.524211</td><td>-1.261496</td><td>-1.410816</td><td>-1.21496</td><td>-0.943442</td><td>1.986899</td><td>-0.019753</td><td>-1.217643</td><td>2.425279</td><td>-0.080253</td><td>0.0</td><td>0.0</td><td>-0.347528</td><td>-0.317906</td><td>-0.45527</td><td>-0.479321</td><td>-0.194527</td><td>-0.199862</td><td>-0.05801</td><td>-0.391492</td><td>0.473886</td><td>-0.220418</td><td>-0.337185</td><td>0.654231</td><td>-0.316881</td><td>7</td></tr><tr><td>1359</td><td>0</td><td>1</td><td>1.413127</td><td>2.944739</td><td>-0.449057</td><td>0.310592</td><td>1.332943</td><td>2.228261</td><td>-0.308488</td><td>0.851587</td><td>0.574776</td><td>-0.531986</td><td>0.134146</td><td>0.583333</td><td>0.141002</td><td>-0.77292</td><td>4.313714</td><td>0.317823</td><td>0.0</td><td>0.207595</td><td>0.0</td><td>-1.617025</td><td>-2.119984</td><td>-0.025225</td><td>0.074288</td><td>0.293362</td><td>0.180437</td><td>-0.229156</td><td>-0.318933</td><td>-1.677353</td><td>-0.136319</td><td>0.463709</td><td>-0.238748</td><td>-1.099758</td><td>0.058065</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>-0.623788</td><td>0.0</td><td>-1.050706</td><td>2.110111</td><td>0.0</td><td>0.924037</td><td>0.524254</td><td>3.851669</td><td>-0.388955</td><td>0.63682</td><td>-0.88224</td><td>-1.330283</td><td>-1.439945</td><td>-1.012512</td><td>4.215051</td><td>0.343801</td><td>-1.119219</td><td>2.736124</td><td>0.043281</td><td>0.0</td><td>0.0</td><td>0.207296</td><td>0.19957</td><td>-0.278074</td><td>-0.260069</td><td>-0.599824</td><td>-0.319232</td><td>-0.802312</td><td>-0.3617</td><td>0.502022</td><td>-0.173755</td><td>-0.201655</td><td>0.720056</td><td>-0.09412</td><td>7</td></tr><tr><td>1359</td><td>0</td><td>2</td><td>1.518645</td><td>2.242425</td><td>-0.404063</td><td>0.465731</td><td>1.737105</td><td>2.552789</td><td>-0.255517</td><td>1.035678</td><td>0.58726</td><td>-0.124289</td><td>0.987805</td><td>0.166667</td><td>0.109462</td><td>-1.615565</td><td>0.445302</td><td>-0.472148</td><td>0.0</td><td>1.143563</td><td>0.0</td><td>-2.157037</td><td>-0.79123</td><td>-0.275964</td><td>-1.115692</td><td>-0.344736</td><td>-0.750789</td><td>-1.104792</td><td>-1.28049</td><td>0.85386</td><td>0.512554</td><td>-0.16115</td><td>-0.635355</td><td>-0.640427</td><td>-0.962834</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>-0.922758</td><td>0.0</td><td>-0.712226</td><td>2.420122</td><td>0.0</td><td>4.606506</td><td>1.734409</td><td>3.851669</td><td>3.454577</td><td>0.689913</td><td>1.884014</td><td>-1.826468</td><td>-1.584165</td><td>-1.112662</td><td>0.124197</td><td>-0.610694</td><td>-1.114943</td><td>1.06576</td><td>-0.701126</td><td>0.0</td><td>0.0</td><td>0.841072</td><td>1.343543</td><td>-0.085355</td><td>-0.065144</td><td>-0.302588</td><td>-0.485465</td><td>-0.370119</td><td>0.722382</td><td>0.210889</td><td>0.397347</td><td>1.606368</td><td>0.806006</td><td>1.240832</td><td>7</td></tr><tr><td>1359</td><td>0</td><td>3</td><td>1.342317</td><td>1.995452</td><td>0.197798</td><td>1.008745</td><td>1.815249</td><td>2.355587</td><td>-0.270152</td><td>0.503513</td><td>0.478007</td><td>-0.266015</td><td>0.04878</td><td>0.25</td><td>0.020408</td><td>-1.091128</td><td>1.52646</td><td>-0.205106</td><td>0.0</td><td>-0.303416</td><td>0.0</td><td>-1.541598</td><td>-2.453977</td><td>1.462868</td><td>-0.13117</td><td>-0.486692</td><td>-0.577188</td><td>1.071896</td><td>0.931131</td><td>-0.362029</td><td>-0.696776</td><td>-0.427228</td><td>-0.639676</td><td>-0.538232</td><td>-0.184962</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>-2.398488</td><td>0.0</td><td>-1.530771</td><td>1.76038</td><td>0.0</td><td>-1.498801</td><td>-1.352574</td><td>3.851669</td><td>1.643704</td><td>-0.139378</td><td>-0.024075</td><td>-1.445658</td><td>-2.021217</td><td>-1.145029</td><td>4.12744</td><td>0.186234</td><td>-0.697002</td><td>0.990352</td><td>-0.725536</td><td>0.0</td><td>0.0</td><td>0.47503</td><td>0.359566</td><td>-0.376677</td><td>-0.389206</td><td>-0.352015</td><td>-0.301331</td><td>-0.844495</td><td>-0.188697</td><td>0.510724</td><td>-1.134449</td><td>-0.159172</td><td>0.968843</td><td>-1.236539</td><td>7</td></tr><tr><td>1359</td><td>0</td><td>5</td><td>1.469287</td><td>1.636272</td><td>-0.242845</td><td>0.897076</td><td>1.409509</td><td>2.331006</td><td>-0.437219</td><td>1.261788</td><td>0.440067</td><td>0.116636</td><td>0.02439</td><td>0.833333</td><td>0.317254</td><td>-1.112629</td><td>1.214978</td><td>-0.491099</td><td>0.0</td><td>-0.28322</td><td>0.0</td><td>-1.099059</td><td>-1.299383</td><td>-0.552897</td><td>-0.493447</td><td>0.060737</td><td>0.488685</td><td>-1.262748</td><td>-1.905434</td><td>-1.080464</td><td>0.217649</td><td>0.38157</td><td>-0.587423</td><td>0.065154</td><td>-0.338904</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>-2.845521</td><td>0.0</td><td>-1.888879</td><td>1.667516</td><td>0.0</td><td>-1.724386</td><td>-0.822925</td><td>3.851669</td><td>-0.497117</td><td>-0.124717</td><td>-0.479826</td><td>-1.594099</td><td>-1.410835</td><td>-0.977505</td><td>0.711486</td><td>-0.3419</td><td>-1.320605</td><td>1.337668</td><td>-0.279872</td><td>0.0</td><td>0.0</td><td>-0.173756</td><td>-0.119563</td><td>-0.442301</td><td>-0.354211</td><td>-0.138384</td><td>-0.043467</td><td>0.178531</td><td>0.067827</td><td>1.043191</td><td>-0.044119</td><td>0.325286</td><td>0.970462</td><td>-0.442468</td><td>7</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1370</td><td>967</td><td>32</td><td>2.392336</td><td>-0.970513</td><td>-0.689064</td><td>-0.80464</td><td>0.188512</td><td>0.977977</td><td>0.32006</td><td>-0.866912</td><td>-0.308539</td><td>-0.301335</td><td>0.317073</td><td>1.0</td><td>0.293135</td><td>-0.457903</td><td>1.422804</td><td>0.191951</td><td>0.970012</td><td>0.6943</td><td>0.789821</td><td>-1.27194</td><td>0.420144</td><td>-2.020144</td><td>3.422769</td><td>-0.135455</td><td>1.447991</td><td>2.255607</td><td>1.267027</td><td>2.376685</td><td>-1.019575</td><td>-2.066507</td><td>1.982367</td><td>0.982517</td><td>2.810244</td><td>-0.562868</td><td>&hellip;</td><td>-1.102517</td><td>-0.174381</td><td>-0.910987</td><td>-1.011996</td><td>1.56789</td><td>-0.154542</td><td>0.295458</td><td>-1.430611</td><td>-0.631919</td><td>1.227449</td><td>-0.626681</td><td>-1.369254</td><td>0.151332</td><td>-1.235409</td><td>0.412719</td><td>-0.496586</td><td>2.533943</td><td>0.339227</td><td>-0.35601</td><td>-0.219466</td><td>-0.056391</td><td>-0.544337</td><td>-0.396218</td><td>-0.332147</td><td>-0.177569</td><td>-0.544805</td><td>-0.349197</td><td>-1.771054</td><td>-0.525312</td><td>-1.946798</td><td>0.241072</td><td>0.181044</td><td>0.065421</td><td>0.375176</td><td>0.137428</td><td>0.428109</td><td>8</td></tr><tr><td>1370</td><td>967</td><td>34</td><td>1.911111</td><td>-0.73649</td><td>-0.752915</td><td>-0.448448</td><td>-2.091238</td><td>1.174098</td><td>0.575665</td><td>-1.369187</td><td>-0.839989</td><td>-0.412729</td><td>0.512195</td><td>0.416667</td><td>0.278293</td><td>0.75222</td><td>0.589476</td><td>0.550262</td><td>-0.65345</td><td>-0.386201</td><td>0.178793</td><td>0.189882</td><td>0.992539</td><td>1.233011</td><td>-0.451411</td><td>-0.0366</td><td>-0.15942</td><td>-0.965048</td><td>-0.848866</td><td>-0.814554</td><td>0.773128</td><td>1.620654</td><td>-0.620883</td><td>-0.46228</td><td>-0.668776</td><td>-2.073051</td><td>&hellip;</td><td>0.260011</td><td>-1.327027</td><td>1.263522</td><td>-0.473861</td><td>-0.038519</td><td>-0.612673</td><td>-1.371018</td><td>-0.01813</td><td>-0.632441</td><td>1.227449</td><td>-0.92545</td><td>-1.231382</td><td>-1.325025</td><td>-0.253767</td><td>0.609254</td><td>0.911673</td><td>0.715444</td><td>0.714629</td><td>0.888505</td><td>0.336581</td><td>0.374347</td><td>-0.201689</td><td>-0.212223</td><td>-0.386479</td><td>-0.398518</td><td>-0.311951</td><td>-0.344617</td><td>0.781782</td><td>0.389013</td><td>0.911636</td><td>0.773548</td><td>0.619074</td><td>0.137061</td><td>0.169996</td><td>0.167079</td><td>0.349549</td><td>8</td></tr><tr><td>1370</td><td>967</td><td>35</td><td>2.430476</td><td>-0.390004</td><td>-0.27989</td><td>-1.174875</td><td>-1.348503</td><td>0.674799</td><td>0.373151</td><td>-0.440463</td><td>-0.207015</td><td>-0.349554</td><td>0.134146</td><td>0.583333</td><td>0.141002</td><td>-1.007735</td><td>-0.063938</td><td>-0.620457</td><td>0.788178</td><td>1.076969</td><td>1.082795</td><td>2.103139</td><td>-1.174479</td><td>-0.967522</td><td>2.896023</td><td>0.810477</td><td>1.915284</td><td>2.106562</td><td>2.531167</td><td>0.280818</td><td>-0.315183</td><td>-1.234272</td><td>2.732495</td><td>1.034769</td><td>3.119164</td><td>-1.140089</td><td>&hellip;</td><td>-0.90763</td><td>1.262501</td><td>-0.909521</td><td>0.763333</td><td>-0.589021</td><td>-0.821753</td><td>0.211839</td><td>-0.031535</td><td>0.212399</td><td>1.227449</td><td>0.197552</td><td>1.550038</td><td>0.735273</td><td>1.904985</td><td>-2.053403</td><td>-0.880794</td><td>-0.376071</td><td>-0.642854</td><td>-0.819059</td><td>0.326489</td><td>-0.462855</td><td>-0.437922</td><td>-0.757116</td><td>-0.484134</td><td>-0.847847</td><td>-0.550796</td><td>-0.756279</td><td>-0.96301</td><td>-0.068327</td><td>-0.703112</td><td>-0.115929</td><td>-0.067838</td><td>0.090418</td><td>0.113785</td><td>0.080935</td><td>0.216028</td><td>8</td></tr><tr><td>1370</td><td>967</td><td>37</td><td>0.76466</td><td>0.229862</td><td>-0.130822</td><td>-0.366252</td><td>-1.395082</td><td>0.911715</td><td>0.4517</td><td>-1.112004</td><td>-0.46962</td><td>-0.145647</td><td>0.414634</td><td>0.333333</td><td>0.397032</td><td>2.261843</td><td>3.228687</td><td>1.606249</td><td>-0.026959</td><td>3.196151</td><td>1.266449</td><td>0.302986</td><td>2.11229</td><td>-2.730362</td><td>-0.563215</td><td>-1.667471</td><td>-1.151794</td><td>0.291971</td><td>0.468838</td><td>0.786002</td><td>-0.820648</td><td>-1.309597</td><td>-0.584387</td><td>0.410452</td><td>-0.596625</td><td>-2.088345</td><td>&hellip;</td><td>1.596131</td><td>-0.346931</td><td>-2.968961</td><td>-1.331302</td><td>1.357634</td><td>-0.586922</td><td>-0.455652</td><td>4.387135</td><td>0.839644</td><td>1.227449</td><td>-0.107197</td><td>1.069073</td><td>-0.047615</td><td>-0.130344</td><td>1.360324</td><td>1.553387</td><td>0.90202</td><td>0.810563</td><td>2.457252</td><td>7.613956</td><td>1.643733</td><td>0.941442</td><td>0.807299</td><td>3.846327</td><td>5.864861</td><td>1.441216</td><td>1.966457</td><td>-0.06673</td><td>-1.519372</td><td>-2.203012</td><td>0.209954</td><td>0.102338</td><td>-1.303606</td><td>0.428269</td><td>0.187324</td><td>0.527199</td><td>8</td></tr><tr><td>1370</td><td>967</td><td>38</td><td>2.369803</td><td>-2.181639</td><td>-0.505849</td><td>-1.276395</td><td>-1.8844</td><td>0.714697</td><td>0.497121</td><td>-1.0069</td><td>-0.53133</td><td>-0.045932</td><td>0.609756</td><td>0.083333</td><td>0.96846</td><td>-0.063999</td><td>1.061939</td><td>0.070471</td><td>0.310111</td><td>-0.594612</td><td>-0.354892</td><td>0.534734</td><td>0.847737</td><td>0.298812</td><td>-0.672554</td><td>1.039225</td><td>0.342775</td><td>-0.596313</td><td>-1.145834</td><td>0.491559</td><td>2.176993</td><td>1.500074</td><td>-0.222366</td><td>-0.194396</td><td>-0.640447</td><td>-0.980815</td><td>&hellip;</td><td>-0.78749</td><td>-0.53228</td><td>-1.51308</td><td>0.481858</td><td>0.639605</td><td>-0.229068</td><td>0.381813</td><td>0.041591</td><td>-0.060055</td><td>1.227449</td><td>-0.728712</td><td>1.622727</td><td>-1.399589</td><td>-0.057538</td><td>0.072661</td><td>-0.180173</td><td>0.23044</td><td>-0.010491</td><td>0.08402</td><td>0.437682</td><td>0.31434</td><td>-0.552924</td><td>-0.479731</td><td>-0.52987</td><td>-0.478243</td><td>-0.530913</td><td>-0.49301</td><td>-0.763536</td><td>-0.206797</td><td>-0.814171</td><td>-0.082911</td><td>-0.041642</td><td>-0.408851</td><td>0.157517</td><td>0.056309</td><td>0.298065</td><td>8</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (391_072, 93)\n",
       "┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ responder_ ┆ responder_ ┆ responder_ ┆ partition_ │\n",
       "│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ 6          ┆ 7          ┆ 8          ┆ id         │\n",
       "│ i16     ┆ i16     ┆ i8        ┆ f32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│         ┆         ┆           ┆          ┆   ┆ f32        ┆ f32        ┆ f32        ┆ i64        │\n",
       "╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 1359    ┆ 0       ┆ 0         ┆ 2.136611 ┆ … ┆ -0.337185  ┆ 0.654231   ┆ -0.316881  ┆ 7          │\n",
       "│ 1359    ┆ 0       ┆ 1         ┆ 1.413127 ┆ … ┆ -0.201655  ┆ 0.720056   ┆ -0.09412   ┆ 7          │\n",
       "│ 1359    ┆ 0       ┆ 2         ┆ 1.518645 ┆ … ┆ 1.606368   ┆ 0.806006   ┆ 1.240832   ┆ 7          │\n",
       "│ 1359    ┆ 0       ┆ 3         ┆ 1.342317 ┆ … ┆ -0.159172  ┆ 0.968843   ┆ -1.236539  ┆ 7          │\n",
       "│ 1359    ┆ 0       ┆ 5         ┆ 1.469287 ┆ … ┆ 0.325286   ┆ 0.970462   ┆ -0.442468  ┆ 7          │\n",
       "│ …       ┆ …       ┆ …         ┆ …        ┆ … ┆ …          ┆ …          ┆ …          ┆ …          │\n",
       "│ 1370    ┆ 967     ┆ 32        ┆ 2.392336 ┆ … ┆ 0.375176   ┆ 0.137428   ┆ 0.428109   ┆ 8          │\n",
       "│ 1370    ┆ 967     ┆ 34        ┆ 1.911111 ┆ … ┆ 0.169996   ┆ 0.167079   ┆ 0.349549   ┆ 8          │\n",
       "│ 1370    ┆ 967     ┆ 35        ┆ 2.430476 ┆ … ┆ 0.113785   ┆ 0.080935   ┆ 0.216028   ┆ 8          │\n",
       "│ 1370    ┆ 967     ┆ 37        ┆ 0.76466  ┆ … ┆ 0.428269   ┆ 0.187324   ┆ 0.527199   ┆ 8          │\n",
       "│ 1370    ┆ 967     ┆ 38        ┆ 2.369803 ┆ … ┆ 0.157517   ┆ 0.056309   ┆ 0.298065   ┆ 8          │\n",
       "└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize(df: pl.LazyFrame, data_stats_dict: dict, features: list[str], eps=1e-9) -> pl.DataFrame:\n",
    "    cat_features = ['feature_09', 'feature_10', 'feature_11']\n",
    "    features = [f for f in features if f not in cat_features]\n",
    "        \n",
    "    eps = 1e-8\n",
    "    return df.with_columns(\n",
    "        [(pl.col(col).sub(data_stats_dict[f'{col}_mean'])).truediv(data_stats_dict[f'{col}_std']).add(eps) for col in features]\n",
    "    ).with_columns(\n",
    "        pl.col(f).truediv(data_stats_dict[f'{f}_max']) for f in cat_features\n",
    "    )\n",
    "    \n",
    "FEATURES = [f'feature_{i:02d}' for i in range(79)]\n",
    "\n",
    "cat_features = ['feature_09', 'feature_10', 'feature_11']\n",
    "\n",
    "data_stats = test_ds.filter(pl.col('date_id').ge(start)).select(\n",
    "    pl.col(FEATURES).mean().name.suffix('_mean'),\n",
    "    pl.col(FEATURES).std().name.suffix('_std'),\n",
    "    pl.col(cat_features).max().name.suffix('_max')\n",
    ")\n",
    "\n",
    "data_stats_dict = data_stats.to_dicts()[0]\n",
    "\n",
    "test_ds = standardize(test_ds, data_stats_dict, FEATURES)\n",
    "\n",
    "test_ds = test_ds.fill_nan(None).fill_null(strategy='zero')\n",
    "\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:43:26.217383Z",
     "iopub.status.busy": "2025-01-07T16:43:26.217175Z",
     "iopub.status.idle": "2025-01-07T16:44:01.367573Z",
     "shell.execute_reply": "2025-01-07T16:44:01.366876Z",
     "shell.execute_reply.started": "2025-01-07T16:43:26.217366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "current_day_data : pl.DataFrame | None = None\n",
    "\n",
    "old_dataset = loader.load(start-60, start-1)\\\n",
    "    .select(COLUMNS)\\\n",
    "    .collect() \\\n",
    "    .filter(~pl.col('symbol_id').is_in(to_remove_symbols))\n",
    "\n",
    "old_dataset_stocks = old_dataset['symbol_id'].unique().sort().to_list()\n",
    "\n",
    "old_dataset = standardize(old_dataset, data_stats_dict, FEATURES).fill_nan(None).fill_null(strategy='zero')\n",
    "\n",
    "\n",
    "last_train_date = start-1\n",
    "new_dataset = old_dataset.filter(pl.col('date_id') > start-30)\n",
    "if OLD_DATA_FRACTION > 0:\n",
    "    old_dataset = old_dataset.filter(pl.col('date_id') <= start-30)\n",
    "else:\n",
    "    old_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRELATION_THR = 0.1\n",
    "WINDOW_LEN = 2 if not os.getenv('KAGGLE_IS_COMPETITION_RERUN') else 7\n",
    "past_responders_pivot: pl.DataFrame | None = None\n",
    "current_date_id = -1\n",
    "current_stock_ids = old_dataset_stocks\n",
    "num_dates = 0\n",
    "\n",
    "adjacency_matrices = np.load('/home/lorecampa/projects/jane_street_forecasting/dataset/sources/graph_conv_torch/adjacency_matrices.npy')[:last_train_date+1, :, :]\n",
    "current_corr_matrix = np.load('/home/lorecampa/projects/jane_street_forecasting/dataset/sources/graph_conv_torch/correlations.npy')[last_train_date, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T16:44:01.800212Z",
     "iopub.status.busy": "2025-01-07T16:44:01.799946Z",
     "iopub.status.idle": "2025-01-07T16:44:01.826177Z",
     "shell.execute_reply": "2025-01-07T16:44:01.825150Z",
     "shell.execute_reply.started": "2025-01-07T16:44:01.800188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global BATCH_SIZE, GRADIENT_CLIPPING, N_EPOCHS_PER_TRAIN_MAX, TRAIN_EVERY\n",
    "    global EARLY_STOPPING_DAYS, ES_PATIENCE, OLD_DATA_FRACTION\n",
    "    global MAX_FINE_TUNING_TIME_LIMIT, TIME_LIMIT, FINE_TUNING\n",
    "    global CORRELATION_THR, WINDOW_LEN\n",
    "    global date_idx, new_dataset, old_dataset, current_day_data, last_train_date\n",
    "    global train_dataloader, val_dataloader, train_iterator, val_iterator, adjacency_matrices\n",
    "    global acc_metrics, save_path, start_train, is_training_loop, epoch, best_epoch, best_score\n",
    "    global current_stock_ids, current_date_id, current_corr_matrix, num_dates, past_responders_pivot\n",
    "    global gradient_clipping_decay, gradient_clipping, lr, lr_decay, optimizer\n",
    "\n",
    "    initial_time = time.time()\n",
    "    FINE_TUNING = FINE_TUNING & (initial_time < MAX_FINE_TUNING_TIME_LIMIT)\n",
    "    start_train = start_train if FINE_TUNING else False\n",
    "\n",
    "    if lags is not None:\n",
    "        # print(f\"Date id: {test['date_id'].min()}\")\n",
    "        # new date_id\n",
    "        lags_ = lags.select(\n",
    "            pl.col('date_id').sub(1),\n",
    "            pl.col(['time_id', 'symbol_id']),\n",
    "            pl.col('responder_6_lag_1').alias('responder_6'),\n",
    "        )\n",
    "        if current_day_data is not None:\n",
    "            # print(current_day_data, new_dataset['date_id'].unique().to_list(), old_dataset['date_id'].unique().to_list())\n",
    "            current_day_data = current_day_data.join(lags_, on=['date_id', 'time_id', 'symbol_id'], \n",
    "                                                     how='left').fill_null(0)\n",
    "            current_day_data = current_day_data.select(COLUMNS)\n",
    "            # replacing date id to ensure that adjacency_matrices array is consistent\n",
    "            current_day_data = (\n",
    "                current_day_data\n",
    "                .drop('date_id')\n",
    "                .with_columns(pl.lit(last_train_date + date_idx + 1).cast(pl.Int16).alias('date_id'))\n",
    "                .select(COLUMNS)\n",
    "            )\n",
    "\n",
    "            new_dataset = new_dataset.vstack(current_day_data)\n",
    "            last_adj = current_corr_matrix.copy()\n",
    "            \n",
    "            last_adj[np.arange(len(current_stock_ids)), np.arange(len(current_stock_ids))] = 0\n",
    "            last_adj = (last_adj > CORRELATION_THR).astype(np.int32)[np.newaxis, :, :]\n",
    "            adjacency_matrices = np.concatenate([adjacency_matrices, last_adj], axis=0)\n",
    "            \n",
    "        current_day_data = test\n",
    "\n",
    "        all_combinations = (\n",
    "            lags_.select(['date_id', 'time_id'])\n",
    "            .unique()\n",
    "            .join(pl.DataFrame({'symbol_id': current_stock_ids}, \n",
    "                               schema={'symbol_id': pl.Int8}), how=\"cross\")\n",
    "        )\n",
    "        \n",
    "        pivot_lags = (\n",
    "            all_combinations\n",
    "            .join(lags_, on=['date_id', 'time_id', 'symbol_id'], how=\"left\")\n",
    "            .fill_null(0)\n",
    "            .sort(['date_id', 'time_id', 'symbol_id'])\n",
    "            .pivot(index=['date_id', 'time_id'], values='responder_6', on='symbol_id')\n",
    "            .fill_null(0)\n",
    "        )\n",
    "        \n",
    "        past_responders_pivot = (\n",
    "            pl.concat([past_responders_pivot, pivot_lags], how='diagonal')\n",
    "            .filter(pl.col('date_id') >= current_date_id - WINDOW_LEN - 1)\n",
    "        ) if past_responders_pivot is not None else pivot_lags\n",
    "        \n",
    "        if num_dates >= WINDOW_LEN:\n",
    "            current_corr_matrix = compute_correlation_from_pivot(past_responders_pivot)\n",
    "\n",
    "        if FINE_TUNING and not start_train:\n",
    "            start_train = (date_idx+1) % TRAIN_EVERY == 0\n",
    "            if start_train:\n",
    "                print('Starting new fine tuning')\n",
    "                model.eval()\n",
    "                max_date = new_dataset.select(pl.col('date_id').max()).item()\n",
    "                new_validation_dataset = new_dataset.filter(pl.col('date_id') > max_date - EARLY_STOPPING_DAYS)\n",
    "                new_training_dataset = new_dataset.filter(pl.col('date_id') <= max_date - EARLY_STOPPING_DAYS)\n",
    "                train_days = new_training_dataset['date_id'].unique().sort().to_list()\n",
    "                val_days = new_validation_dataset['date_id'].unique().sort().to_list()\n",
    "                print(f'Training days: {train_days}')\n",
    "                print(f'Validation days: {val_days}')\n",
    "                \n",
    "                if OLD_DATA_FRACTION > 0:\n",
    "                    old_data_len = OLD_DATA_FRACTION * new_training_dataset.shape[0] / (1 - OLD_DATA_FRACTION)\n",
    "                    time_factions = min(1, old_data_len / old_dataset.shape[0])\n",
    "                    old_date_times = old_dataset.select(['date_id', 'time_id']).unique().sample(fraction=time_factions)\n",
    "                                        \n",
    "                    old_training_dataset = old_dataset.join(old_date_times, on=['date_id', 'time_id'], how='inner')\n",
    "                    \n",
    "                    print(f'Old training days: {old_training_dataset[\"date_id\"].unique().to_list()}')\n",
    "                    \n",
    "                    train_dataloader = MultiStockGraphDataset(pl.concat([old_training_dataset, new_training_dataset]), adjacency_matrices.copy(), current_stock_ids)\n",
    "                    val_dataloader = MultiStockGraphDataset(new_validation_dataset, adjacency_matrices.copy(), current_stock_ids)\n",
    "                else:\n",
    "                    train_dataloader = MultiStockGraphDataset(new_training_dataset, adjacency_matrices.copy(), current_stock_ids)\n",
    "                    val_dataloader = MultiStockGraphDataset(new_validation_dataset, adjacency_matrices.copy(), current_stock_ids)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "                train_dataloader = DataLoader(train_dataloader, shuffle=True, batch_size=BATCH_SIZE, num_workers=0)\n",
    "                val_dataloader = DataLoader(val_dataloader, shuffle=False, batch_size=2048, num_workers=0)\n",
    "                val_iterator = iter(val_dataloader)\n",
    "                acc_metrics = dict(ss_res=0.0, ss_tot=0.0)\n",
    "                is_training_loop = False\n",
    "                epoch = -1\n",
    "                best_epoch = -1\n",
    "                best_score = -1e10\n",
    "\n",
    "                if OLD_DATA_FRACTION > 0:\n",
    "                    max_new_date_id = new_training_dataset['date_id'].max()\n",
    "                    old_dataset = old_dataset.vstack(new_training_dataset).filter(\n",
    "                        pl.col('date_id').is_between(max_new_date_id - 30, max_new_date_id)\n",
    "                    )\n",
    "                    \n",
    "                new_dataset = new_validation_dataset\n",
    "                \n",
    "        date_idx += 1\n",
    "    else:\n",
    "        current_day_data = current_day_data.vstack(test)\n",
    "        \n",
    "    if FINE_TUNING:\n",
    "        while start_train and time.time() - initial_time < TIME_LIMIT:\n",
    "            if is_training_loop:\n",
    "                try:\n",
    "                    batch = next(train_iterator)\n",
    "                except StopIteration:\n",
    "                    model.eval()\n",
    "                    val_iterator = iter(val_dataloader)\n",
    "                    acc_metrics = dict(ss_res=0.0, ss_tot=0.0)\n",
    "                    is_training_loop = False\n",
    "                    continue\n",
    "        \n",
    "                x, targets, m, w, s, A = batch\n",
    "                optimizer.zero_grad()\n",
    "                y_out = model.forward(x.to(device), s.to(device), A.to(device)).squeeze()\n",
    "                loss = loss_fn(y_out, targets.to(device), w.to(device))\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                optimizer.step()\n",
    "                \n",
    "            else:\n",
    "                try:\n",
    "                    batch = next(val_iterator)\n",
    "                except StopIteration:\n",
    "                    score = 1 - acc_metrics['ss_res'] / acc_metrics['ss_tot']\n",
    "                    print(f'Epoch {epoch} completed with score {score}')\n",
    "                    epoch += 1\n",
    "                    if score > best_score:\n",
    "                        torch.save(model.state_dict(), save_path)\n",
    "                        inference_model.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "                        inference_model.to(device)\n",
    "                        inference_model.eval()\n",
    "                        best_epoch = epoch\n",
    "                        best_score = score\n",
    "                    if epoch - best_epoch >= ES_PATIENCE or epoch == N_EPOCHS_PER_TRAIN_MAX:\n",
    "                        print(f'Stopping after {epoch} epochs')\n",
    "                        print(f'Completed Fine Tuning at time {test.select(pl.col(\"time_id\").first()).item()}')\n",
    "                        model.load_state_dict(torch.load(save_path, weights_only=True))\n",
    "                        model.to(device)\n",
    "                        model.eval()\n",
    "                        start_train = False\n",
    "                        lr *= lr_decay\n",
    "                        gradient_clipping *= gradient_clipping_decay\n",
    "                        break\n",
    "                    model.train()\n",
    "                    train_iterator = iter(train_dataloader)\n",
    "                    is_training_loop = True\n",
    "                    continue\n",
    "\n",
    "                x, targets, m, w, s, A = batch\n",
    "                with torch.no_grad():\n",
    "                    y_out = model(x.to(device), s.to(device), A.to(device)).squeeze()\n",
    "                w = w.to(device)\n",
    "                targets = targets.to(device)\n",
    "                acc_metrics['ss_res'] += (w * (y_out - targets) ** 2).sum().cpu()\n",
    "                acc_metrics['ss_tot'] += (w * (targets ** 2)).sum().cpu()\n",
    "\n",
    "    if test.select(pl.col('is_scored').cast(pl.Int8).first()).item() > 0:\n",
    "        test_ = test.fill_nan(None).fill_null(strategy='zero')\n",
    "        predict_df = (\n",
    "            test_.select(['date_id', 'time_id'])\n",
    "                .unique()\n",
    "                .join(pl.DataFrame({'symbol_id': list(range(39))}, \n",
    "                                schema={'symbol_id': pl.Int8}), how=\"cross\")\n",
    "                .join(test_.with_columns(pl.lit(1).alias('mask')), \n",
    "                    on=['date_id', 'time_id', 'symbol_id'], how=\"left\")\n",
    "                .fill_null(0)  # fill all columns with 0 for missing stocks (including the mask)\n",
    "                .sort(['date_id', 'time_id', 'symbol_id'])\n",
    "        )\n",
    "        valid_data = predict_df.select(['mask']).to_numpy().flatten() == 1\n",
    "        x = torch.tensor(predict_df.select([f'feature_{i:02d}' for i in range(79)]).to_numpy().reshape(-1, 39, 79), dtype=torch.float32).to(device)\n",
    "        s = torch.tensor(predict_df.select(['symbol_id']).to_numpy().flatten().reshape(-1, 39).astype(np.int32)).to(device)\n",
    "        # adj = adjacency_matrices[predict_df.select(pl.col('date_id').first()).item()][np.newaxis, :, :]\n",
    "        # adj = torch.tensor(adj, dtype=torch.int, device=device).repeat(x.shape[0], 1, 1)\n",
    "        \n",
    "        adj_matrix = current_corr_matrix.copy()\n",
    "        adj_matrix[np.arange(39), np.arange(39)] = 0\n",
    "        adj_matrix = (adj_matrix > CORRELATION_THR).astype(np.int32)\n",
    "        adj_matrix = torch.tensor(adj_matrix, dtype=torch.int, device=device).unsqueeze(0).repeat(x.shape[0], 1, 1)\n",
    "        with torch.no_grad():\n",
    "            preds = inference_model(x, s, adj_matrix).cpu().numpy().flatten()[valid_data]\n",
    "        predict_df = predict_df.filter(pl.col('mask') == 1).with_columns(pl.Series(preds).alias('responder_6'))\n",
    "        \n",
    "        predictions = test.join(predict_df, on=['time_id', 'symbol_id'], how='left').select(['row_id', 'responder_6'])\n",
    "    else:\n",
    "        predictions = test.select('row_id', pl.Series(np.zeros(test.shape[0])).alias('responder_6'))\n",
    "    predictions = predictions.with_columns(pl.col('responder_6').cast(pl.Float32))\n",
    "\n",
    "    if isinstance(predictions, pl.DataFrame):\n",
    "        assert predictions.columns == ['row_id', 'responder_6']\n",
    "    elif isinstance(predictions, pd.DataFrame):\n",
    "        assert (predictions.columns == ['row_id', 'responder_6']).all()\n",
    "    else:\n",
    "        raise TypeError('The predict function must return a DataFrame')\n",
    "    \n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new fine tuning\n",
      "Training days: [1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352]\n",
      "Validation days: [1353, 1354, 1355, 1356, 1357, 1358, 1359]\n",
      "Old training days: [1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m y_hat_iterator \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (test, lags) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(online_iterator_daily(test_ds, show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# print(len(test))\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     y_hat_iterator\u001b[38;5;241m.\u001b[39mappend(res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponder_6\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy())\n\u001b[1;32m     11\u001b[0m y_hat_iterator \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(y_hat_iterator) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_hat_iterator) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 174\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(test, lags)\u001b[0m\n\u001b[1;32m    172\u001b[0m x, targets, m, w, s, A \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 174\u001b[0m     y_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    175\u001b[0m w \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    176\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 63\u001b[0m, in \u001b[0;36mStockGCNModel.forward\u001b[0;34m(self, x, symbols, adj)\u001b[0m\n\u001b[1;32m     61\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, stock_embeddings], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_projector(x)\n\u001b[0;32m---> 63\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(x)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(output)\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m, in \u001b[0;36mGraphConvEncoder.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     23\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(edge_indices, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mGraphConvEncoderLayer.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     25\u001b[0m residual \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(batch_size \u001b[38;5;241m*\u001b[39m num_nodes, num_features)\n\u001b[0;32m---> 27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(batch_size, num_nodes, num_features)        \n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x) \u001b[38;5;241m+\u001b[39m residual\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:109\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[1;32m    108\u001b[0m deg \u001b[38;5;241m=\u001b[39m scatter(edge_weight, idx, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, dim_size\u001b[38;5;241m=\u001b[39mnum_nodes, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mdeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    111\u001b[0m edge_weight \u001b[38;5;241m=\u001b[39m deg_inv_sqrt[row] \u001b[38;5;241m*\u001b[39m edge_weight \u001b[38;5;241m*\u001b[39m deg_inv_sqrt[col]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from nbs.tabm.predict_tabm import predict_tabm\n",
    "from prj.utils import online_iterator, online_iterator_daily\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_hat_iterator = []\n",
    "for i, (test, lags) in enumerate(online_iterator_daily(test_ds, show_progress=True)):\n",
    "    # print(len(test))\n",
    "    res = predict(test, lags)\n",
    "    y_hat_iterator.append(res['responder_6'].to_numpy())\n",
    "    \n",
    "y_hat_iterator = np.concatenate(y_hat_iterator) if len(y_hat_iterator) > 0 else None\n",
    "\n",
    "\n",
    "score = r2_score(y_test, y_hat_iterator, sample_weight=w_test)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.013081669807434082\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.011371493339538574"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 6315458,
     "sourceId": 10394435,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 213404970,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 214901608,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 215844687,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 215868163,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
