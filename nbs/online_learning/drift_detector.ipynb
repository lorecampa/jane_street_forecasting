{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set([28 * i for i in range(1, 10000)])\n",
    "b = set([39 * i for i in range(1, 10000)])\n",
    "\n",
    "sorted(list(a & b))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prj.config import DATA_DIR\n",
    "from prj.data.data_loader import DataConfig, DataLoader\n",
    "\n",
    "\n",
    "data_args = {}\n",
    "config = DataConfig(**data_args)\n",
    "loader = DataLoader(data_dir=DATA_DIR, config=config)\n",
    "test_ds = loader.load(1600, 1605).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19342295, 0.40621698, 0.20757085, 0.35800211, 0.65921724,\n",
       "       0.36698247, 0.27399136, 0.81355452, 0.19647356, 0.63540672])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.rand(10).clip(-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "\n",
    "def online_iterator(df: pl.DataFrame, show_progress: bool = True):\n",
    "    assert df.select('date_id').n_unique() > 1, 'Dataset must contain at least 2 days'\n",
    "    \n",
    "    df_date_time_id = df.select('date_id', 'time_id').unique().sort('date_id', 'time_id').with_row_index('date_time_id')\n",
    "    df = df.join(df_date_time_id, on=['date_id', 'time_id'], how='left', maintain_order='left')\n",
    "    \n",
    "    max_date_time_id = df_date_time_id['date_time_id'].max()\n",
    "    min_date_id = df.select('date_id').min().item()\n",
    "    \n",
    "    responders = [f'responder_{i}' for i in range(9)]\n",
    "    \n",
    "    curr_idx:int = df_date_time_id.filter(pl.col('date_id').eq(min_date_id + 1))['date_time_id'].min()\n",
    "    old_day = min_date_id\n",
    "\n",
    "    \n",
    "    with tqdm(total=max_date_time_id - curr_idx + 1, disable=not show_progress) as pbar:\n",
    "        while curr_idx <= max_date_time_id:\n",
    "            curr_day = df_date_time_id[curr_idx]['date_id'].item()\n",
    "            is_new_day = curr_day != old_day\n",
    "            lags = None\n",
    "            if is_new_day:\n",
    "                lags = df.filter(pl.col('date_id').eq(old_day)).select(pl.col('date_id').add(1), 'time_id', 'symbol_id', *[pl.col(r).alias(f'{r}_lag_1') for r in responders])\n",
    "            \n",
    "            old_day = curr_day\n",
    "\n",
    "            batch = df.filter(pl.col('date_time_id').eq(curr_idx)).with_columns(pl.lit(True).alias('is_scored')).drop('date_time_id')\n",
    "            \n",
    "            yield batch, lags if lags is not None else None\n",
    "            \n",
    "            curr_idx += 1\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4840 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch, lags in online_iterator(test_ds):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import polars as pl\n",
    "from river.drift import ADWIN\n",
    "\n",
    "class DriftDetector:\n",
    "    def __init__(self, features, drift_detector_factory=ADWIN, delta=0.05, drift_threshold=0.5):\n",
    "        self.detectors = defaultdict(lambda: drift_detector_factory(delta=delta))\n",
    "        self.drift_detector_factory = drift_detector_factory\n",
    "        self.delta = delta\n",
    "        self.features = features\n",
    "        self.drift_threshold=drift_threshold\n",
    "\n",
    "    def update(self, data: pl.DataFrame):\n",
    "        drift_results = defaultdict(dict)\n",
    "        data = data.select('date_id', 'time_id', 'symbol_id', *self.features)\n",
    "        for row in data.iter_rows(named=True):\n",
    "            symbol = row['symbol_id']\n",
    "\n",
    "            for feature in self.features:\n",
    "                value = row[feature]\n",
    "                if value is None:\n",
    "                    continue\n",
    "            \n",
    "                detector = self.detectors[(symbol, feature)]\n",
    "                detector.update(value)\n",
    "                \n",
    "                drift_detected = detector.drift_detected\n",
    "                drift_results[symbol][feature] = drift_detected\n",
    "\n",
    "        return drift_results\n",
    "\n",
    "    def check_drift(self, drift_results):\n",
    "        drift_summary = {}\n",
    "\n",
    "        for symbol, features in drift_results.items():\n",
    "            drift_summary[symbol] = False\n",
    "            total_features = len(features)\n",
    "            drifted_features = sum(drift_detected for drift_detected in features.values())\n",
    "            if drifted_features / total_features >= self.drift_threshold:\n",
    "                drift_summary[symbol] = True\n",
    "\n",
    "        return drift_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4840 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/4840 [00:00<00:37, 129.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 979/4840 [00:14<00:56, 68.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1005/4840 [00:15<01:00, 63.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 35, 36] Date: 1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1946/4840 [00:29<00:39, 72.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1962/4840 [00:29<00:45, 62.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 11, 14, 20] Date: 1603\n",
      "[16] Date: 1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2912/4840 [00:44<00:31, 61.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 3885/4840 [00:59<00:18, 53.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 3915/4840 [01:00<00:15, 59.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24] Date: 1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4840/4840 [01:15<00:00, 64.05it/s]\n"
     ]
    }
   ],
   "source": [
    "detector = DriftDetector(features=loader.features)\n",
    "i = 0\n",
    "for batch, lags in online_iterator(test_ds):\n",
    "    if lags is not None:\n",
    "        print(batch['date_id'].min())\n",
    "    drift_result = detector.update(batch)\n",
    "    drift_summary = detector.check_drift(drift_result)\n",
    "    symbols_drifted = [k for k, v in drift_summary.items() if v]\n",
    "    if len(symbols_drifted) > 0:\n",
    "        print(symbols_drifted, f\"Date: {batch['date_id'].min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
