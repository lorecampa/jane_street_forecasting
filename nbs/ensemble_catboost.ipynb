{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from prj.oamp.oamp import OAMP\n",
    "from prj.oamp.oamp_config import ConfigOAMP\n",
    "import os, sys, gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import kaggle_evaluation.jane_street_inference_server\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import joblib\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor, Booster\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:03<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 1414-1420\n",
      "Skipping 1415-1420\n",
      "Skipping 1416-1420\n",
      "Skipping 1417-1420\n",
      "Skipping 1418-1420\n",
      "Skipping 1419-1420\n",
      "Skipping 1420-1420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2187680, 134)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prj.config import DATA_DIR\n",
    "from prj.data.data_loader import PARTITIONS_DATE_INFO, DataConfig, DataLoader\n",
    "\n",
    "data_args = data_args = {'include_time_id': True, 'include_intrastock_norm_temporal': True}\n",
    "config = DataConfig(**data_args)\n",
    "loader = DataLoader(data_dir=DATA_DIR, config=config)\n",
    "\n",
    "start, end = 1360, 1360 + 30*2\n",
    "test_ds = loader.load(start, end).sort('date_id', 'time_id', 'symbol_id')\n",
    "features = loader.features\n",
    "X, y, w, info = loader._build_splits(test_ds)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091904"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_test_idx = test_ds.with_row_index().filter(pl.col('date_id').lt(1360+30)).collect().shape[0]\n",
    "start_test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling lgbm models: 100%|██████████| 2/2 [00:00<00:00, 14.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from lleaves import Model\n",
    "from pathlib import Path\n",
    "\n",
    "lgbm_model_files = [\n",
    "    \"/home/lorecampa/projects/jane_street_forecasting/dataset/models/lgbm/lgbm_maxbin_63_0_7_324272949.txt\",\n",
    "    \"/home/lorecampa/projects/jane_street_forecasting/dataset/models/lgbm/lgbm_maxbin_63_0_7_3234493111.txt\"\n",
    "]\n",
    "lgbm_agents = [\n",
    "    Model(model_file=file) for file in lgbm_model_files\n",
    "]\n",
    "for i in tqdm(range(len(lgbm_agents)), desc='Compiling lgbm models'):\n",
    "    lgbm_agents[i].compile(cache=Path(lgbm_model_files[i]).with_suffix('.o'))\n",
    "\n",
    "\n",
    "lgbm_agents_label = ['lgbm_1', 'lgbm_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.86s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2187680, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_predictions = np.concatenate([agent.predict(X).reshape(-1, 1) for agent in tqdm(lgbm_agents)], axis=1)\n",
    "lgbm_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import os\n",
    "from typing import List, Union, Dict, Any\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    return 'cpu'\n",
    "\n",
    "class JaneStreetMultiStockGraphDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset: pl.LazyFrame, adjacency_matrices: np.ndarray, num_stocks: int = 39):\n",
    "        self.dataset = dataset\n",
    "        self.adjacency_matrices = adjacency_matrices\n",
    "        self.num_stocks = num_stocks\n",
    "        self.dataset_len = self.dataset.select(['date_id', 'time_id']).unique().collect().shape[0]\n",
    "        self._load()\n",
    "    \n",
    "    def _load(self):\n",
    "        all_combinations = (\n",
    "            self.dataset.select(['date_id', 'time_id'])\n",
    "            .unique()\n",
    "            .join(pl.DataFrame({'symbol_id': list(range(self.num_stocks))}, \n",
    "                               schema={'symbol_id': pl.Int8}).lazy(), how=\"cross\")\n",
    "        )\n",
    "        feature_cols = [f'feature_{i:02d}' for i in range(79)]\n",
    "        self.batch = (\n",
    "            all_combinations\n",
    "            .join(self.dataset.with_columns(pl.lit(1).alias('mask')), \n",
    "                  on=['date_id', 'time_id', 'symbol_id'], how=\"left\")\n",
    "            .fill_null(0)  # fill all columns with 0 for missing stocks (including the mask)\n",
    "            .sort(['date_id', 'time_id', 'symbol_id'])\n",
    "        )\n",
    "        # num_stocks rows for each date and time\n",
    "        self.X = self.batch.select(feature_cols).collect().to_numpy().astype(np.float32)\n",
    "        self.y = self.batch.select(['responder_6']).collect().to_numpy().flatten().astype(np.float32)\n",
    "        self.s = self.batch.select(['symbol_id']).collect().to_numpy().flatten().astype(np.int32)\n",
    "        self.date_ids = self.batch.select(['date_id']).collect().to_numpy().flatten()\n",
    "        self.masks = self.batch.select(['mask']).collect().to_numpy().flatten() == 0\n",
    "        self.weights = self.batch.select(['weight']).collect().to_numpy().flatten().astype(np.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start_row = idx * self.num_stocks\n",
    "        features = self.X[start_row:start_row+self.num_stocks, :]\n",
    "        targets = self.y[start_row:start_row+self.num_stocks]\n",
    "        masks = self.masks[start_row:start_row+self.num_stocks]\n",
    "        weights = self.weights[start_row:start_row+self.num_stocks]\n",
    "        symbols = self.s[start_row:start_row+self.num_stocks]\n",
    "\n",
    "        date_id = self.date_ids[start_row]\n",
    "        adj_matrix = self.adjacency_matrices[date_id]\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(features), \n",
    "            torch.tensor(targets), \n",
    "            torch.tensor(masks), \n",
    "            torch.tensor(weights), \n",
    "            torch.tensor(symbols),\n",
    "            torch.tensor(adj_matrix, dtype=torch.int)\n",
    "        )\n",
    "        \n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "    \n",
    "    def forward(self, predictions: Tensor, targets: Tensor, weights: Tensor) -> Tensor:\n",
    "        squared_diff = (predictions - targets) ** 2\n",
    "        weighted_squared_diff = weights * squared_diff\n",
    "        return weighted_squared_diff.sum() / weights.sum()\n",
    "    \n",
    "class TransposeLayer(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return input.transpose(1, 2)\n",
    "    \n",
    "class GraphConvEncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, dim_feedforward_mult=4, dropout_rate=0.1):\n",
    "        super(GraphConvEncoderLayer, self).__init__()\n",
    "        \n",
    "        self.graph_conv = GCNConv(\n",
    "            in_channels=hidden_dim, \n",
    "            out_channels=hidden_dim\n",
    "        )\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * dim_feedforward_mult),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim * dim_feedforward_mult, hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        batch_size, num_nodes, num_features = x.size()\n",
    "\n",
    "        residual = x\n",
    "        x = x.reshape(batch_size * num_nodes, num_features)\n",
    "        x = self.graph_conv(x, edge_index)\n",
    "        x = x.reshape(batch_size, num_nodes, num_features)        \n",
    "        x = self.dropout1(x) + residual\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.feedforward(x)\n",
    "        x = self.dropout2(x) + residual\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "class GraphConvEncoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, dim_feedforward_mult=4, dropout_rate=0.1):\n",
    "        super(GraphConvEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            GraphConvEncoderLayer(\n",
    "                hidden_dim=hidden_dim,\n",
    "                dim_feedforward_mult=dim_feedforward_mult,\n",
    "                dropout_rate=dropout_rate\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        batch_size, num_nodes, _ = x.size()\n",
    "\n",
    "        edge_indices = []\n",
    "        for batch_idx in range(batch_size):\n",
    "            adj_matrix = adj[batch_idx]\n",
    "            src, tgt = torch.nonzero(adj_matrix, as_tuple=True)\n",
    "            src = src + batch_idx * num_nodes\n",
    "            tgt = tgt + batch_idx * num_nodes\n",
    "            edge_indices.append(torch.stack([src, tgt], dim=0))\n",
    "\n",
    "        edge_index = torch.cat(edge_indices, dim=1).to(x.device)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class StockGCNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_features,\n",
    "        hidden_dim=64,\n",
    "        output_dim=1,\n",
    "        num_layers=2,\n",
    "        num_stocks=39,\n",
    "        embedding_dim=16,\n",
    "        use_embeddings=False,\n",
    "        dropout_rate=0.2,\n",
    "        dim_feedforward_mult=4,\n",
    "    ):\n",
    "        super(StockGCNModel, self).__init__()\n",
    "\n",
    "        self.use_embeddings = use_embeddings\n",
    "\n",
    "        self.init_layers = nn.Sequential(\n",
    "            # TransposeLayer(),\n",
    "            # nn.BatchNorm1d(input_features),\n",
    "            # TransposeLayer(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.feature_projector = []\n",
    "        if use_embeddings:\n",
    "            self.feature_projector.append(nn.Linear(input_features + embedding_dim, hidden_dim))\n",
    "            self.embedding_layer = nn.Embedding(num_stocks, embedding_dim)\n",
    "        else:\n",
    "            self.feature_projector.append(nn.Linear(input_features, hidden_dim))\n",
    "        self.feature_projector += [\n",
    "            # TransposeLayer(),\n",
    "            # nn.BatchNorm1d(hidden_dim),\n",
    "            # TransposeLayer(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        ]\n",
    "        self.feature_projector = nn.Sequential(*self.feature_projector)\n",
    "\n",
    "        self.encoder = GraphConvEncoder(\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dim_feedforward_mult=dim_feedforward_mult,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            # TransposeLayer(),\n",
    "            # nn.BatchNorm1d(hidden_dim),\n",
    "            # TransposeLayer(),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, symbols, adj):\n",
    "        batch_size, num_stocks, num_features = x.size()\n",
    "\n",
    "        x = self.init_layers(x)\n",
    "        if self.use_embeddings:\n",
    "            stock_embeddings = self.embedding_layer(symbols)\n",
    "            x = torch.cat([x, stock_embeddings], dim=-1)\n",
    "        x = self.feature_projector(x)\n",
    "        x = self.encoder(x, adj)\n",
    "\n",
    "        output = self.predictor(x)\n",
    "        return 5 * torch.tanh(output)\n",
    "    \n",
    "    def predict(self, dl, device):\n",
    "        with torch.no_grad():\n",
    "            y_out = []\n",
    "            for x, targets, m, w, s, A in dl:\n",
    "                    y_out.append(self(x.to(device), s.to(device), A.to(device)).squeeze().cpu().numpy())\n",
    "            \n",
    "            return np.concatenate(y_out)\n",
    "                \n",
    "    \n",
    "def evaluate_model(model, val_dl, device):\n",
    "    ss_res = 0.0\n",
    "    ss_tot = 0.0\n",
    "    for x, targets, m, w, s, A in val_dl:\n",
    "        with torch.no_grad():\n",
    "            y_out = model(x.to(device), s.to(device), A.to(device)).squeeze()\n",
    "        w = w.to(device)\n",
    "        targets = targets.to(device)\n",
    "        ss_res += (w * (y_out - targets) ** 2).sum().cpu()\n",
    "        ss_tot += (w * (targets ** 2)).sum().cpu()\n",
    "    return 1 - ss_res / ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrices = np.load('/home/lorecampa/projects/jane_street_forecasting/dataset/sources/graph_conv_torch/adjacency_matrices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = '/home/lorecampa/projects/jane_street_forecasting/dataset/models/graph_conv/model_3_7.pth'\n",
    "model = StockGCNModel(\n",
    "    input_features=79,\n",
    "    output_dim=1,\n",
    "    num_layers=1,\n",
    "    dropout_rate=0.2,\n",
    "    dim_feedforward_mult=4,\n",
    "    hidden_dim=64\n",
    ")\n",
    "model.load_state_dict(torch.load(save_path, weights_only=True, map_location=torch.device(device)))\n",
    "model = model.to(device)\n",
    "\n",
    "graph_conv_models = [model]\n",
    "graph_conv_agents_label = ['graph_conv_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2302872, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = JaneStreetMultiStockGraphDataset(test_ds, adjacency_matrices)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2048, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "graph_conv_predictions = model.predict(test_dataloader, device).flatten().reshape(-1, 1)\n",
    "graph_conv_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2187680, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2187680, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.concatenate([lgbm_predictions], axis=1)\n",
    "agent_labels = ['lgbm_1', 'lgbm_2']\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from prj.metrics import weighted_mae, weighted_mse, weighted_rmse\n",
    "\n",
    "def metrics(y_true, y_pred, weights):\n",
    "    \n",
    "    return {\n",
    "        'r2_w': r2_score(y_true, y_pred, sample_weight=weights),\n",
    "        'mae_w': weighted_mae(y_true, y_pred, weights=weights),\n",
    "        'mse_w': weighted_mse(y_true, y_pred, weights=weights),\n",
    "        'rmse_w': weighted_rmse(y_true, y_pred, weights=weights),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0245501\ttotal: 15.7ms\tremaining: 1.56s\n",
      "50:\tlearn: 1.0206023\ttotal: 753ms\tremaining: 723ms\n",
      "99:\tlearn: 1.0189951\ttotal: 1.47s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor(iterations=100, learning_rate=0.01, depth=5, task_type='GPU')\n",
    "\n",
    "X_train, y_train, w_train = predictions[:start_test_idx, :], y[:start_test_idx], w[:start_test_idx]\n",
    "X_test, y_test, w_test = predictions[start_test_idx:, :], y[start_test_idx:], w[start_test_idx:]\n",
    "\n",
    "\n",
    "X_train = np.concatenate([X[:start_test_idx, :], lgbm_predictions[:start_test_idx, :]], axis=1)\n",
    "\n",
    "model.fit(X_train, y_train, sample_weight=None, verbose=50)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "res = metrics(y_test, y_pred, w_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_w</th>\n",
       "      <th>mae_w</th>\n",
       "      <th>mse_w</th>\n",
       "      <th>rmse_w</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.014817</td>\n",
       "      <td>0.541524</td>\n",
       "      <td>0.710560</td>\n",
       "      <td>0.842947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.014817</td>\n",
       "      <td>0.541524</td>\n",
       "      <td>0.710560</td>\n",
       "      <td>0.842947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm_2</th>\n",
       "      <td>0.014490</td>\n",
       "      <td>0.541683</td>\n",
       "      <td>0.710796</td>\n",
       "      <td>0.843087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm_1</th>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.710885</td>\n",
       "      <td>0.843140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble</th>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.541728</td>\n",
       "      <td>0.713317</td>\n",
       "      <td>0.844581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              r2_w     mae_w     mse_w    rmse_w\n",
       "Agent                                           \n",
       "mean      0.014817  0.541524  0.710560  0.842947\n",
       "median    0.014817  0.541524  0.710560  0.842947\n",
       "lgbm_2    0.014490  0.541683  0.710796  0.843087\n",
       "lgbm_1    0.014368  0.541667  0.710885  0.843140\n",
       "ensemble  0.010996  0.541728  0.713317  0.844581"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from prj.metrics import weighted_mae, weighted_mse, weighted_rmse\n",
    "\n",
    "def metrics(y_true, y_pred, weights):\n",
    "    return {\n",
    "        'r2_w': r2_score(y_true, y_pred, sample_weight=weights),\n",
    "        'mae_w': weighted_mae(y_true, y_pred, weights=weights),\n",
    "        'mse_w': weighted_mse(y_true, y_pred, weights=weights),\n",
    "        'rmse_w': weighted_rmse(y_true, y_pred, weights=weights),\n",
    "    }\n",
    "    \n",
    "results = {}\n",
    "columns = list(res.keys())\n",
    "results['ensemble'] = res.values()\n",
    "for i in range(len(agent_labels)):\n",
    "    results[agent_labels[i]] = metrics(y[start_test_idx:], predictions[start_test_idx:, i], w[start_test_idx:]).values()\n",
    "results['mean'] = metrics(y[start_test_idx:], np.mean(predictions[start_test_idx:], axis=1), w[start_test_idx:]).values()\n",
    "results['median'] = metrics(y[start_test_idx:], np.median(predictions[start_test_idx:], axis=1), w[start_test_idx:]).values()\n",
    "\n",
    "\n",
    "results = pl.DataFrame(results)\\\n",
    "    .transpose(include_header=True, column_names=columns, header_name='Agent')\\\n",
    "    .sort('r2_w', descending=True) \\\n",
    "    .to_pandas().set_index('Agent')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
