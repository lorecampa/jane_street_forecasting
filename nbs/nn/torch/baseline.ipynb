{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 16:26:49.853756: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-18 16:26:49.853787: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-18 16:26:49.855029: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-18 16:26:49.861402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-18 16:26:50.582758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import os\n",
    "from typing import List, Union, Dict, Any\n",
    "\n",
    "from prj.data.data_loader import DataLoader as BaseDataLoader\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from prj.model.torch.datasets.base import JaneStreetBaseDataset\n",
    "from prj.model.torch.losses import WeightedMSELoss\n",
    "from prj.model.torch.models.mlp import Mlp\n",
    "from prj.model.torch.wrappers.base import JaneStreetModelWrapper\n",
    "from prj.model.torch.utils import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prj.config import DATA_DIR\n",
    "from prj.data.data_loader import DataConfig\n",
    "\n",
    "data_args = {'zero_fill': True}\n",
    "config = DataConfig(**data_args)\n",
    "loader = BaseDataLoader(data_dir=DATA_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N rows train: 13495856, ES: 1457808, VAL: 3692920\n",
      "N dates train: 366, ES: 41, VAL: 102\n"
     ]
    }
   ],
   "source": [
    "start_dt, end_dt = 1020, 1529\n",
    "# start_dt, end_dt = 1020, 1100\n",
    "val_ratio = 0.2\n",
    "es_ratio = 0.1\n",
    "early_stopping = True\n",
    "\n",
    "train_ds, val_ds = loader.load_train_and_val(start_dt=start_dt, end_dt=end_dt, val_ratio=val_ratio)        \n",
    "es_ds = None\n",
    "if early_stopping:\n",
    "    train_dates = train_ds.select('date_id').unique().collect().to_series().sort()\n",
    "    split_point = int(len(train_dates) * (1 - es_ratio))\n",
    "    split_date = train_dates[split_point]\n",
    "    es_ds = train_ds.filter(pl.col('date_id').ge(split_date))\n",
    "    train_ds = train_ds.filter(pl.col('date_id').lt(split_date))\n",
    "\n",
    "n_rows_train = train_ds.select(pl.len()).collect().item()\n",
    "n_dates_train = train_ds.select('date_id').unique().collect().count().item()\n",
    "n_rows_es = es_ds.select(pl.len()).collect().item() if early_stopping else 0\n",
    "n_dates_es = es_ds.select('date_id').unique().collect().count().item() if early_stopping else 0\n",
    "n_rows_val = val_ds.select(pl.len()).collect().item()\n",
    "n_dates_val = val_ds.select('date_id').unique().collect().count().item()\n",
    "print(f'N rows train: {n_rows_train}, ES: {n_rows_es}, VAL: {n_rows_val}')\n",
    "print(f'N dates train: {n_dates_train}, ES: {n_dates_es}, VAL: {n_dates_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = JaneStreetBaseDataset(train_ds, features=loader.features)\n",
    "if early_stopping:\n",
    "    es_ds = JaneStreetBaseDataset(es_ds, features=loader.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = 'ReduceLROnPlateau'\n",
    "scheduler_cfg = dict(mode='min', factor=0.1, patience=3, verbose=True, min_lr=1e-8)\n",
    "model = Mlp(input_dim=(len(loader.features),), hidden_dims=[256, 128, 64], use_dropout=True, use_bn=False)\n",
    "model = JaneStreetModelWrapper(\n",
    "    model, \n",
    "    [WeightedMSELoss()], \n",
    "    [1], \n",
    "    scheduler=scheduler, \n",
    "    scheduler_cfg=scheduler_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/lorecampa/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "   | Name          | Type            | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0  | model         | Mlp             | 61.7 K | train\n",
      "1  | model.model   | Sequential      | 61.7 K | train\n",
      "2  | model.model.0 | Linear          | 20.5 K | train\n",
      "3  | model.model.1 | LeakyReLU       | 0      | train\n",
      "4  | model.model.2 | Dropout         | 0      | train\n",
      "5  | model.model.3 | Linear          | 32.9 K | train\n",
      "6  | model.model.4 | LeakyReLU       | 0      | train\n",
      "7  | model.model.5 | Dropout         | 0      | train\n",
      "8  | model.model.6 | Linear          | 8.3 K  | train\n",
      "9  | model.model.7 | LeakyReLU       | 0      | train\n",
      "10 | model.model.8 | Dropout         | 0      | train\n",
      "11 | model.model.9 | Linear          | 65     | train\n",
      "12 | losses        | ModuleList      | 0      | train\n",
      "13 | losses.0      | WeightedMSELoss | 0      | train\n",
      "-----------------------------------------------------------\n",
      "61.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "61.7 K    Total params\n",
      "0.247     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5eca04d4eb47b983667117930f476f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 0 - Validation]\n",
      "val_wmse: 3.1414\n",
      "val_wmse_epoch: 3.1414\n",
      "val_wmae: 1.2893\n",
      "val_wmae_epoch: 1.2893\n",
      "val_wr2: -0.1392\n",
      "val_wr2_epoch: -0.1392\n",
      "val_loss: 3.1414\n",
      "val_loss_epoch: 3.1414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82da4c1f73d54e2c8dce619d60174911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "If you really know what your doing, you can silence this warning with the warning module\n",
      "or by setting POLARS_ALLOW_FORKING_THREAD=1.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b498b50124c143599318e4bf387cf3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_wr2 improved. New best score: -0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 0 - Validation]\n",
      "val_wmse: 0.7383\n",
      "val_wmse_epoch: 0.7383\n",
      "val_wmae: 0.5515\n",
      "val_wmae_epoch: 0.5515\n",
      "val_wr2: -0.0000\n",
      "val_wr2_epoch: -0.0000\n",
      "val_loss: 0.7383\n",
      "val_loss_epoch: 0.7383\n",
      "\n",
      "[Epoch 0 - Training]\n",
      "train_wmse: 0.7201\n",
      "train_wmse_step: 0.9726\n",
      "train_wmae: 0.5460\n",
      "train_wmae_step: 0.5787\n",
      "train_wr2: -0.0007\n",
      "train_wr2_step: -0.0003\n",
      "train_loss: 0.7201\n",
      "train_loss_step: 0.9726\n",
      "train_wmse_epoch: 0.7201\n",
      "train_wmae_epoch: 0.5460\n",
      "train_wr2_epoch: -0.0007\n",
      "train_loss_epoch: 0.7201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcafea3ad76d4b1c9168e70f759608d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1 - Validation]\n",
      "val_wmse: 0.7383\n",
      "val_wmse_epoch: 0.7383\n",
      "val_wmae: 0.5514\n",
      "val_wmae_epoch: 0.5514\n",
      "val_wr2: -0.0000\n",
      "val_wr2_epoch: -0.0000\n",
      "val_loss: 0.7383\n",
      "val_loss_epoch: 0.7383\n",
      "\n",
      "[Epoch 1 - Training]\n",
      "train_wmse: 0.7196\n",
      "train_wmse_step: 0.6711\n",
      "train_wmae: 0.5458\n",
      "train_wmae_step: 0.5558\n",
      "train_wr2: -0.0000\n",
      "train_wr2_step: 0.0006\n",
      "train_loss: 0.7196\n",
      "train_loss_step: 0.6711\n",
      "train_wmse_epoch: 0.7196\n",
      "train_wmae_epoch: 0.5458\n",
      "train_wr2_epoch: -0.0000\n",
      "train_loss_epoch: 0.7196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc02975ee23849b987231663feb97942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2 - Validation]\n",
      "val_wmse: 0.7383\n",
      "val_wmse_epoch: 0.7383\n",
      "val_wmae: 0.5517\n",
      "val_wmae_epoch: 0.5517\n",
      "val_wr2: -0.0000\n",
      "val_wr2_epoch: -0.0000\n",
      "val_loss: 0.7383\n",
      "val_loss_epoch: 0.7383\n",
      "\n",
      "[Epoch 2 - Training]\n",
      "train_wmse: 0.7196\n",
      "train_wmse_step: 0.5750\n",
      "train_wmae: 0.5458\n",
      "train_wmae_step: 0.5162\n",
      "train_wr2: -0.0000\n",
      "train_wr2_step: -0.0000\n",
      "train_loss: 0.7196\n",
      "train_loss_step: 0.5750\n",
      "train_wmse_epoch: 0.7196\n",
      "train_wmae_epoch: 0.5458\n",
      "train_wr2_epoch: -0.0000\n",
      "train_loss_epoch: 0.7196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d136ce87da984bcd9ebd676c089bc60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 3 - Validation]\n",
      "val_wmse: 0.7383\n",
      "val_wmse_epoch: 0.7383\n",
      "val_wmae: 0.5518\n",
      "val_wmae_epoch: 0.5518\n",
      "val_wr2: -0.0000\n",
      "val_wr2_epoch: -0.0000\n",
      "val_loss: 0.7383\n",
      "val_loss_epoch: 0.7383\n",
      "\n",
      "[Epoch 3 - Training]\n",
      "train_wmse: 0.7196\n",
      "train_wmse_step: 0.5677\n",
      "train_wmae: 0.5458\n",
      "train_wmae_step: 0.4896\n",
      "train_wr2: -0.0000\n",
      "train_wr2_step: 0.0002\n",
      "train_loss: 0.7196\n",
      "train_loss_step: 0.5677\n",
      "train_wmse_epoch: 0.7196\n",
      "train_wmae_epoch: 0.5458\n",
      "train_wr2_epoch: -0.0000\n",
      "train_loss_epoch: 0.7196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7391f761fb804efc8bfbcfc872f960d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 4 - Validation]\n",
      "val_wmse: 0.7383\n",
      "val_wmse_epoch: 0.7383\n",
      "val_wmae: 0.5518\n",
      "val_wmae_epoch: 0.5518\n",
      "val_wr2: -0.0000\n",
      "val_wr2_epoch: -0.0000\n",
      "val_loss: 0.7383\n",
      "val_loss_epoch: 0.7383\n",
      "\n",
      "[Epoch 4 - Training]\n",
      "train_wmse: 0.7196\n",
      "train_wmse_step: 0.6982\n",
      "train_wmae: 0.5458\n",
      "train_wmae_step: 0.5369\n",
      "train_wr2: -0.0000\n",
      "train_wr2_step: -0.0006\n",
      "train_loss: 0.7196\n",
      "train_loss_step: 0.6982\n",
      "train_wmse_epoch: 0.7196\n",
      "train_wmae_epoch: 0.5458\n",
      "train_wr2_epoch: -0.0000\n",
      "train_loss_epoch: 0.7196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4475df5aab54adcb67d513f1f8f70e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_wr2 did not improve in the last 5 records. Best score: -0.000. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 5 - Validation]\n",
      "val_wmse: 0.7383\n",
      "val_wmse_epoch: 0.7383\n",
      "val_wmae: 0.5514\n",
      "val_wmae_epoch: 0.5514\n",
      "val_wr2: -0.0000\n",
      "val_wr2_epoch: -0.0000\n",
      "val_loss: 0.7383\n",
      "val_loss_epoch: 0.7383\n",
      "\n",
      "[Epoch 5 - Training]\n",
      "train_wmse: 0.7196\n",
      "train_wmse_step: 0.6510\n",
      "train_wmae: 0.5458\n",
      "train_wmae_step: 0.5306\n",
      "train_wr2: 0.0000\n",
      "train_wr2_step: 0.0001\n",
      "train_loss: 0.7196\n",
      "train_loss_step: 0.6510\n",
      "train_wmse_epoch: 0.7196\n",
      "train_wmae_epoch: 0.5458\n",
      "train_wr2_epoch: 0.0000\n",
      "train_loss_epoch: 0.7196\n"
     ]
    }
   ],
   "source": [
    "early_stopping = {'monitor': 'val_wr2', 'min_delta': 0.00, 'patience': 5, 'verbose': True, 'mode': 'max'}\n",
    "batch_size = 1024\n",
    "num_workers = 3\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "es_dataloader = DataLoader(es_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers) if early_stopping else None\n",
    "\n",
    "\n",
    "model: JaneStreetModelWrapper = train(model, train_dataloader, es_dataloader, accelerator='auto',\n",
    "                                max_epochs=20, precision='32-true', use_model_ckpt=False, \n",
    "                                gradient_clip_val=10, use_early_stopping=True, \n",
    "                                early_stopping_cfg=early_stopping, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3692920, 79), (3692920,), (3692920,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, y_val, w_val, _ = loader._build_splits(val_ds)\n",
    "X_val.shape, y_val.shape, w_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3692920,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_val)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r2_w': -3.075599670410156e-05,\n",
       " 'mae_w': 0.50378007,\n",
       " 'mse_w': 0.6111065,\n",
       " 'rmse_w': 0.78173304}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prj.metrics import weighted_mae, weighted_mse, weighted_r2, weighted_rmse\n",
    "\n",
    "{\n",
    "    'r2_w': weighted_r2(y_val, y_hat, weights=w_val),\n",
    "    'mae_w': weighted_mae(y_val, y_hat, weights=w_val),\n",
    "    'mse_w': weighted_mse(y_val, y_hat, weights=w_val),\n",
    "    'rmse_w': weighted_rmse(y_val, y_hat, weights=w_val),\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
