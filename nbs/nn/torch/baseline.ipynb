{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 02:23:18.156318: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-14 02:23:18.156352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-14 02:23:18.157817: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-14 02:23:18.164628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-14 02:23:18.879007: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import os\n",
    "from typing import List, Union, Dict, Any\n",
    "\n",
    "from prj.data.data_loader import DataLoader as BaseDataLoader\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from prj.model.torch.datasets.base import JaneStreetBaseDataset\n",
    "from prj.model.torch.losses import WeightedMSELoss\n",
    "from prj.model.torch.models.mlp import Mlp\n",
    "from prj.model.torch.wrappers.base import JaneStreetModelWrapper\n",
    "from prj.model.torch.utils import train\n",
    "from prj.config import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pl.concat([\n",
    "    pl.scan_parquet(DATA_DIR / f'partition_id={i}' / 'part-0.parquet')\n",
    "    for i in range(8, 9)\n",
    "])\n",
    "val_ds = pl.scan_parquet(DATA_DIR / 'partition_id=9' / 'part-0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JaneStreetBaseDataset(train_ds, ffill=True, num_days_batch=250)\n",
    "val_dataset = JaneStreetBaseDataset(val_ds, shuffle=False, ffill=True, num_days_batch=250)\n",
    "\n",
    "# shuffle is not needed as it's already done in the dataset\n",
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/lorecampa/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name          | Type            | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model         | Mlp             | 53.5 K | train\n",
      "1 | model.model   | Sequential      | 53.5 K | train\n",
      "2 | model.model.0 | Linear          | 20.5 K | train\n",
      "3 | model.model.1 | LeakyReLU       | 0      | train\n",
      "4 | model.model.2 | Linear          | 32.9 K | train\n",
      "5 | model.model.3 | LeakyReLU       | 0      | train\n",
      "6 | model.model.4 | Linear          | 129    | train\n",
      "7 | losses        | ModuleList      | 0      | train\n",
      "8 | losses.0      | WeightedMSELoss | 0      | train\n",
      "----------------------------------------------------------\n",
      "53.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.5 K    Total params\n",
      "0.214     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1b8bcefca149999f190961d8ae8b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorecampa/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 0 - Validation]\n",
      "val_wmse: 7.3915\n",
      "val_wmse_epoch: 7.3915\n",
      "val_wmae: 2.1831\n",
      "val_wmae_epoch: 2.1831\n",
      "val_wr2: -2.7058\n",
      "val_wr2_epoch: -2.7058\n",
      "val_loss: 7.3915\n",
      "val_loss_epoch: 7.3915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorecampa/projects/jane_street_forecasting/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8747438b4fe049309473f2459c95e30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef45c0f876a441e0b57adf4587c14498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 0 - Validation]\n",
      "val_wmse: 0.6201\n",
      "val_wmse_epoch: 0.6201\n",
      "val_wmae: 0.5167\n",
      "val_wmae_epoch: 0.5167\n",
      "val_wr2: 0.0004\n",
      "val_wr2_epoch: 0.0004\n",
      "val_loss: 0.6201\n",
      "val_loss_epoch: 0.6201\n",
      "\n",
      "[Epoch 0 - Training]\n",
      "train_wmse: 0.6868\n",
      "train_wmse_step: 0.5372\n",
      "train_wmae: 0.5339\n",
      "train_wmae_step: 0.5255\n",
      "train_wr2: 0.0031\n",
      "train_wr2_step: -0.0177\n",
      "train_loss: 0.6868\n",
      "train_loss_step: 0.5372\n",
      "train_wmse_epoch: 0.6868\n",
      "train_wmae_epoch: 0.5339\n",
      "train_wr2_epoch: 0.0031\n",
      "train_loss_epoch: 0.6868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JaneStreetModelWrapper(\n",
       "  (model): Mlp(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=79, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (losses): ModuleList(\n",
       "    (0): WeightedMSELoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from prj.config import EXP_DIR\n",
    "\n",
    "\n",
    "scheduler = 'ReduceLROnPlateau'\n",
    "scheduler_cfg = dict(mode='min', factor=0.1, patience=3, verbose=True, min_lr=1e-8)\n",
    "base_model3 = Mlp(input_dim=(79,), hidden_dims=[256, 128], use_dropout=False, use_bn=False)\n",
    "model_no_bn_and_dropout = JaneStreetModelWrapper(base_model3, [WeightedMSELoss()], [1], \n",
    "                                              scheduler=scheduler, scheduler_cfg=scheduler_cfg)\n",
    "\n",
    "\n",
    "# dir_path = str(EXP_DIR / 'tmp' / f'model3_{time.time()}')\n",
    "# os.makedirs(dir_path, exist_ok=True)\n",
    "# ckpt_config = {'dirpath': dir_path, 'filename': 'baseline_no_all', 'save_top_k': 1,\n",
    "#                'monitor': 'val_wr2', 'verbose': True, 'mode': 'max'}\n",
    "early_stopping = {'monitor': 'val_wr2', 'min_delta': 0.00, 'patience': 5, 'verbose': True, 'mode': 'max'}\n",
    "model_no_bn_and_dropout = train(model_no_bn_and_dropout, train_dataloader, val_dataloader, accelerator='auto',\n",
    "                                max_epochs=1, precision='32-true', use_model_ckpt=False, \n",
    "                                gradient_clip_val=20, use_early_stopping=False, \n",
    "                                early_stopping_cfg=early_stopping, compile=False)\n",
    "\n",
    "# base_model3 = Mlp(79, hidden_dims=[256, 128], use_dropout=False, use_bn=False)\n",
    "# model_no_bn_and_dropout = JaneStreetModelWrapper.load_from_checkpoint(\n",
    "#     f\"{dir_path}/baseline_no_all.ckpt\", \n",
    "#     model=base_model3,\n",
    "#     losses=[WeightedMSELoss()], \n",
    "#     loss_weights=[1])\n",
    "\n",
    "model_no_bn_and_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3064/3064 [03:13<00:00, 15.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001715540885925293"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from prj.model.torch.metrics import weighted_r2_score\n",
    "\n",
    "val_dataset = JaneStreetBaseDataset(val_ds, ffill=True, num_days_batch=250)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "model = model_no_bn_and_dropout\n",
    "y_hat_all = []\n",
    "y = []\n",
    "weights = []\n",
    "model.eval()\n",
    "for x, targets, w in tqdm(iter(val_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        preds_all = model(x)\n",
    "    y_hat_all.append(preds_all.numpy().flatten())\n",
    "    y.append(targets.numpy().flatten())\n",
    "    weights.append(w.numpy().flatten())\n",
    "\n",
    "y = np.concatenate(y)\n",
    "y_hat_all = np.concatenate(y_hat_all)\n",
    "weights = np.concatenate(weights)\n",
    "weighted_r2_score(y_hat_all, y, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset._load_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6274576, 79), (6274576,), (6274576,), (6274576,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, w = val_dataset.X, val_dataset.y, val_dataset.weights\n",
    "X.shape, y.shape, w.shape, y_hat_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_x = model(torch.from_numpy(X))\n",
    "y_hat_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_r2_score(y_hat_x, y, weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
