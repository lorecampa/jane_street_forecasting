{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from prj.config import DATA_DIR\n",
    "\n",
    "\n",
    "BASE_PATH = DATA_DIR / 'train'\n",
    "\n",
    "\n",
    "partition=5\n",
    "train_ds = pl.concat([\n",
    "    pl.read_parquet(BASE_PATH / f'partition_id={i}' / 'part-0.parquet')\n",
    "    for i in range(partition, partition + 1)\n",
    "]).sort('date_id', 'time_id', 'symbol_id')\n",
    "features = [col for col in train_ds.columns if col.startswith('feature_')]\n",
    "target_feature = 'responder_6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 84)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>&hellip;</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_50</th><th>feature_51</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_6</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>850</td><td>0</td><td>0</td><td>2.087724</td><td>-0.276877</td><td>-2.385324</td><td>-1.086325</td><td>0.049463</td><td>3.427029</td><td>-4.671824</td><td>0.054977</td><td>-0.259751</td><td>1.343003</td><td>11</td><td>7</td><td>76</td><td>-0.793587</td><td>2.523406</td><td>0.303231</td><td>null</td><td>0.523913</td><td>null</td><td>-1.567069</td><td>-0.965586</td><td>0.014156</td><td>-0.171976</td><td>1.015679</td><td>0.746074</td><td>-1.633316</td><td>-1.309486</td><td>0.965614</td><td>1.612443</td><td>0.82306</td><td>-0.027811</td><td>0.72484</td><td>-0.184198</td><td>null</td><td>&hellip;</td><td>0.050192</td><td>null</td><td>-0.954613</td><td>2.004981</td><td>-1.557791</td><td>0.678891</td><td>-0.066386</td><td>null</td><td>2.456588</td><td>null</td><td>null</td><td>-1.159385</td><td>null</td><td>-0.889724</td><td>1.428067</td><td>null</td><td>0.817551</td><td>0.299599</td><td>0.352903</td><td>-0.328996</td><td>-0.151735</td><td>-0.224472</td><td>-1.477134</td><td>-1.643559</td><td>-0.556531</td><td>2.815019</td><td>0.356358</td><td>-0.527251</td><td>1.609195</td><td>0.076337</td><td>null</td><td>null</td><td>-0.228297</td><td>-0.273781</td><td>-0.277999</td><td>-0.295312</td><td>1.461546</td></tr><tr><td>850</td><td>0</td><td>1</td><td>3.752097</td><td>-0.168178</td><td>-2.161023</td><td>-0.511679</td><td>0.192425</td><td>3.162096</td><td>-4.386098</td><td>0.130385</td><td>-0.368283</td><td>1.913416</td><td>11</td><td>7</td><td>76</td><td>-0.660111</td><td>3.052153</td><td>0.071869</td><td>null</td><td>0.001913</td><td>null</td><td>-0.625688</td><td>-1.11523</td><td>0.185483</td><td>0.019226</td><td>1.916643</td><td>0.710887</td><td>-1.102333</td><td>-0.981141</td><td>0.521467</td><td>1.665925</td><td>1.461316</td><td>-0.358575</td><td>0.058004</td><td>0.021168</td><td>null</td><td>&hellip;</td><td>1.311157</td><td>null</td><td>-0.749923</td><td>1.793136</td><td>-2.108881</td><td>1.227915</td><td>-0.146708</td><td>null</td><td>0.888707</td><td>null</td><td>null</td><td>-1.427895</td><td>null</td><td>-1.575317</td><td>0.556004</td><td>null</td><td>0.321817</td><td>0.406464</td><td>0.352903</td><td>-0.388503</td><td>-0.100457</td><td>-0.201082</td><td>-1.926849</td><td>-1.763679</td><td>-0.612577</td><td>1.61283</td><td>-0.051637</td><td>-0.97052</td><td>2.79455</td><td>0.353143</td><td>null</td><td>null</td><td>-0.157027</td><td>-0.163802</td><td>-0.277016</td><td>-0.444008</td><td>0.789595</td></tr><tr><td>850</td><td>0</td><td>2</td><td>1.225099</td><td>-0.520426</td><td>-1.718115</td><td>-0.817358</td><td>-0.270528</td><td>3.314825</td><td>-2.578923</td><td>0.1102</td><td>-0.20174</td><td>2.072351</td><td>81</td><td>2</td><td>59</td><td>-0.528026</td><td>3.354508</td><td>0.327966</td><td>null</td><td>-0.215615</td><td>null</td><td>-1.260532</td><td>-2.04301</td><td>-1.31462</td><td>-0.239955</td><td>0.017958</td><td>-0.27587</td><td>-0.705935</td><td>-0.782762</td><td>0.268385</td><td>1.391267</td><td>1.265022</td><td>-0.539895</td><td>-0.351402</td><td>-0.209022</td><td>null</td><td>&hellip;</td><td>-1.394171</td><td>null</td><td>-1.067848</td><td>0.734942</td><td>-2.05364</td><td>-1.888152</td><td>-0.688585</td><td>null</td><td>-0.588629</td><td>null</td><td>null</td><td>-2.212862</td><td>null</td><td>-2.015984</td><td>0.025982</td><td>null</td><td>-4.632971</td><td>-2.559358</td><td>0.352903</td><td>-0.316812</td><td>-0.264718</td><td>-0.248274</td><td>-1.383873</td><td>-2.433391</td><td>-0.728091</td><td>4.478824</td><td>0.497227</td><td>-0.449675</td><td>1.648489</td><td>-0.001233</td><td>null</td><td>null</td><td>-0.012737</td><td>-0.081892</td><td>-0.209053</td><td>-0.267447</td><td>-2.848316</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 84)\n",
       "┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ feature_76 ┆ feature_77 ┆ feature_78 ┆ responder_ │\n",
       "│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ 6          │\n",
       "│ i16     ┆ i16     ┆ i8        ┆ f32      ┆   ┆ f32        ┆ f32        ┆ f32        ┆ ---        │\n",
       "│         ┆         ┆           ┆          ┆   ┆            ┆            ┆            ┆ f32        │\n",
       "╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 850     ┆ 0       ┆ 0         ┆ 2.087724 ┆ … ┆ -0.273781  ┆ -0.277999  ┆ -0.295312  ┆ 1.461546   │\n",
       "│ 850     ┆ 0       ┆ 1         ┆ 3.752097 ┆ … ┆ -0.163802  ┆ -0.277016  ┆ -0.444008  ┆ 0.789595   │\n",
       "│ 850     ┆ 0       ┆ 2         ┆ 1.225099 ┆ … ┆ -0.081892  ┆ -0.209053  ┆ -0.267447  ┆ -2.848316  │\n",
       "└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [f'feature_00', 'feature_01', 'feature_02']\n",
    "features = [col for col in train_ds.columns if col.startswith('feature_')]\n",
    "numerical_features = features\n",
    "categorical_features = []\n",
    "time_cols = ['date_id', 'time_id']\n",
    "\n",
    "train_ds = train_ds.select(time_cols + ['symbol_id', 'weight'] + features + [target_feature])\n",
    "train_ds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column</th><th>count</th><th>count (%)</th></tr><tr><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;feature_39&quot;</td><td>375700</td><td>7.024793</td></tr><tr><td>&quot;feature_42&quot;</td><td>375700</td><td>7.024793</td></tr><tr><td>&quot;feature_50&quot;</td><td>375700</td><td>7.024793</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────────┬────────┬───────────┐\n",
       "│ column     ┆ count  ┆ count (%) │\n",
       "│ ---        ┆ ---    ┆ ---       │\n",
       "│ str        ┆ u32    ┆ f64       │\n",
       "╞════════════╪════════╪═══════════╡\n",
       "│ feature_39 ┆ 375700 ┆ 7.024793  │\n",
       "│ feature_42 ┆ 375700 ┆ 7.024793  │\n",
       "│ feature_50 ┆ 375700 ┆ 7.024793  │\n",
       "└────────────┴────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prj.utils import get_null_count\n",
    "get_null_count(train_ds).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column</th><th>count</th><th>count (%)</th></tr><tr><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;feature_21&quot;</td><td>94764</td><td>1.771886</td></tr><tr><td>&quot;feature_26&quot;</td><td>94764</td><td>1.771886</td></tr><tr><td>&quot;feature_27&quot;</td><td>94764</td><td>1.771886</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌────────────┬───────┬───────────┐\n",
       "│ column     ┆ count ┆ count (%) │\n",
       "│ ---        ┆ ---   ┆ ---       │\n",
       "│ str        ┆ u32   ┆ f64       │\n",
       "╞════════════╪═══════╪═══════════╡\n",
       "│ feature_21 ┆ 94764 ┆ 1.771886  │\n",
       "│ feature_26 ┆ 94764 ┆ 1.771886  │\n",
       "│ feature_27 ┆ 94764 ┆ 1.771886  │\n",
       "└────────────┴───────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = train_ds.with_columns(\n",
    "    pl.col(features).fill_nan(None).forward_fill(limit=100).over('symbol_id').name.keep()\n",
    ")\n",
    "get_null_count(train_ds).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column</th><th>count</th><th>count (%)</th></tr><tr><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;date_id&quot;</td><td>0</td><td>0.0</td></tr><tr><td>&quot;time_id&quot;</td><td>0</td><td>0.0</td></tr><tr><td>&quot;symbol_id&quot;</td><td>0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 3)\n",
       "┌───────────┬───────┬───────────┐\n",
       "│ column    ┆ count ┆ count (%) │\n",
       "│ ---       ┆ ---   ┆ ---       │\n",
       "│ str       ┆ u32   ┆ f64       │\n",
       "╞═══════════╪═══════╪═══════════╡\n",
       "│ date_id   ┆ 0     ┆ 0.0       │\n",
       "│ time_id   ┆ 0     ┆ 0.0       │\n",
       "│ symbol_id ┆ 0     ┆ 0.0       │\n",
       "└───────────┴───────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the other nulls\n",
    "train_ds = train_ds.with_columns(\n",
    "    pl.col(features).fill_null(0.)\n",
    ")\n",
    "get_null_count(train_ds).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prj.utils import build_rolling_stats\n",
    "\n",
    "# rolling_stats = build_rolling_stats(train_ds, cols=numerical_features, window=30)\n",
    "# rolling_stats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prj.utils import moving_z_score_norm\n",
    "\n",
    "# train_ds = moving_z_score_norm(train_ds, rolling_stats_df=rolling_stats, cols=numerical_features, clip_bound=None)\n",
    "# train_ds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4278560, 79), (4278560,), (4278560,), (1069640, 79), (1069640,), (1069640,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_ds.select(features).to_pandas()\n",
    "y = train_ds[target_feature].to_numpy()\n",
    "w = train_ds['weight'].to_numpy()\n",
    "\n",
    "X_train = X.iloc[:int(0.8 * len(X))]\n",
    "y_train = y[:int(0.8 * len(y))]\n",
    "w_train = w[:int(0.8 * len(w))]\n",
    "X_val = X.iloc[int(0.8 * len(X)):]\n",
    "y_val = y[int(0.8 * len(y)):]\n",
    "w_val = w[int(0.8 * len(w)):]\n",
    "\n",
    "X_train.shape, y_train.shape, w_train.shape, X_val.shape, y_val.shape, w_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prj.model.nn.mlp import MLP\n",
    "\n",
    "model = MLP(\n",
    "    input_dim=X_train.shape[1:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with early stopping patience 5\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 79)]              0         \n",
      "                                                                 \n",
      " Dense0 (Dense)              (None, 128)               10240     \n",
      "                                                                 \n",
      " BatchNormalization0 (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " Activation0 (Activation)    (None, 128)               0         \n",
      "                                                                 \n",
      " Dropout0 (Dropout)          (None, 128)               0         \n",
      "                                                                 \n",
      " OutputDense (Dense)         (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10881 (42.50 KB)\n",
      "Trainable params: 10625 (41.50 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "16714/16714 [==============================] - 53s 3ms/step - loss: 2.1485 - r2_score: -0.0324 - mean_squared_error: 0.7599 - val_loss: 2.4683 - val_r2_score: 0.0084 - val_mean_squared_error: 0.7166\n",
      "Epoch 2/5\n",
      "16714/16714 [==============================] - 65s 4ms/step - loss: 2.0191 - r2_score: 0.0100 - mean_squared_error: 0.7287 - val_loss: 2.4485 - val_r2_score: 0.0103 - val_mean_squared_error: 0.7152\n",
      "Epoch 3/5\n",
      "16714/16714 [==============================] - 119s 7ms/step - loss: 2.0052 - r2_score: 0.0134 - mean_squared_error: 0.7262 - val_loss: 2.4436 - val_r2_score: 0.0111 - val_mean_squared_error: 0.7146\n",
      "Epoch 4/5\n",
      "16714/16714 [==============================] - 135s 8ms/step - loss: 2.0007 - r2_score: 0.0146 - mean_squared_error: 0.7253 - val_loss: 2.4414 - val_r2_score: 0.0114 - val_mean_squared_error: 0.7144\n",
      "Epoch 5/5\n",
      "16714/16714 [==============================] - 122s 7ms/step - loss: 1.9983 - r2_score: 0.0154 - mean_squared_error: 0.7247 - val_loss: 2.4432 - val_r2_score: 0.0108 - val_mean_squared_error: 0.7149\n",
      "Fit complete after 5\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers as tfko\n",
    "from keras import metrics as tfkm\n",
    "from prj.model.nn.losses import WeightedZeroMeanR2Loss \n",
    "optimizer = tfko.Adam(learning_rate=1e-4)\n",
    "loss = WeightedZeroMeanR2Loss()\n",
    "metrics = [tfkm.R2Score(), tfkm.MeanSquaredError()]\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    sample_weight=w_train,\n",
    "    validation_data=(X_val, y_val, w_val),\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer, \n",
    "    loss=loss, \n",
    "    early_stopping_rounds=5,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179/4179 [==============================] - 2s 519us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from prj.metrics import weighted_r2\n",
    "\n",
    "\n",
    "weighted_r2(y_val, y_pred, weights=w_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179/4179 [==============================] - 2s 369us/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from prj.metrics import weighted_mae, weighted_mse, weighted_r2, weighted_rmse\n",
    "\n",
    "def evaluate(X: np.ndarray, y: np.ndarray, weights: np.ndarray = None) -> float:\n",
    "    y_pred = model.model.predict(X, batch_size=256)  \n",
    "    return {\n",
    "        'r2_w': weighted_r2(y, y_pred, weights=weights),\n",
    "        'mae_w': weighted_mae(y, y_pred, weights=weights),\n",
    "        'mse_w': weighted_mse(y, y_pred, weights=weights),\n",
    "        'rmse_w': weighted_rmse(y, y_pred, weights=weights),\n",
    "    }\n",
    "    \n",
    "evaluate(X_val, y_val, w_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
